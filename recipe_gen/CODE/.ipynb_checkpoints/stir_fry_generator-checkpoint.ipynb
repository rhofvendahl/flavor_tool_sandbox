{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas==1.0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "import math\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.dirname(os.getcwd())\n",
    "ingredients_data_raw = pd.read_csv(os.path.join(root_path, 'DATA/ingredients_data.csv'))\n",
    "ingredients_data = ingredients_data_raw.replace(float('nan'), '')\n",
    "stir_fry_data_impractical = ingredients_data[ingredients_data['stir_fry']=='y']\n",
    "stir_fry_data_all = stir_fry_data_impractical[(stir_fry_data_impractical['stir_fry_umbrella'] != 'y') & (stir_fry_data_impractical['redirect'] != 'y')]\n",
    "stir_fry_data = stir_fry_data_all[stir_fry_data_all['stir_fry_yes'] == 'y']\n",
    "\n",
    "stir_fry_data_basic = stir_fry_data[stir_fry_data['stir_fry_basic'] == 'y']\n",
    "# stir_fry_data_current = stir_fry_data[stir_fry_data['2020_7_5'] == 'y']\n",
    "# stir_fry_data_with_umbrella = ingredients_data[(ingredients_data['stir_fry_umbrella'] != 'y') & (ingredients_data['stir_fry'] == 'y')]\n",
    "# stir_fry_data = stir_fry_data_basic\n",
    "# stir_fry_data = stir_fry_data_current\n",
    "# stir_fry_data = stir_fry_data_with_umbrella\n",
    "stir_fry_data_is_basic = False\n",
    "\n",
    "stir_fry_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Matching \"pairs with\" terms to ingredient names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terms_from_pairs_with(pairs_with):\n",
    "    if str(pairs_with) == 'nan':\n",
    "        return []\n",
    "    else:\n",
    "        return [term.strip() for term in pairs_with.split('\\n\\n') if term.strip() != '']\n",
    "\n",
    "# break entries in column that has 'pairs with' strings into lists of ingredient terms\n",
    "ingredient_pairs_with_terms = stir_fry_data['pairs_with'].apply(get_terms_from_pairs_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create list of all terms, ignoring case and excluding duplicates\n",
    "# all_terms = list(set(ingredient_pairs_with_terms.sum()))\n",
    "# all_terms_lower = list(set([term.lower() for term in ingredient_pairs_with_terms.sum()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install inflect\n",
    "# import inflect\n",
    "# p = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salad_matches = pd.read_csv(os.path.join(root_path, 'DATA/term_name_matches_specific.csv'))\n",
    "    \n",
    "# def get_tokens(phrase):\n",
    "#     tokens = [token.strip() for token in re.split('\\(|\\)|,|e\\.g\\.|esp\\.|and|—|or|aka|see|see also|;|and\\/or|\\*', phrase)]\n",
    "# #     print(tokens)\n",
    "#     tokens = [p.singular_noun(token) or token for token in tokens if token != '']\n",
    "# #     print(tokens)\n",
    "#     return tokens\n",
    "\n",
    "# def get_mark(name, term):\n",
    "# #     print()\n",
    "# #     print('NAME', name)\n",
    "# #     print('TERM', term)\n",
    "#     try:\n",
    "#         salad_match = salad_matches[term][salad_matches['name'] == name].iloc[0]\n",
    "# #         print('SALAD MATCH', salad_match)\n",
    "#     except:\n",
    "# #         print('NO SALAD MATCH')\n",
    "#         salad_match = None \n",
    "#     if salad_match:\n",
    "#         if str(salad_match) in ['0', 'nan']:\n",
    "# #             print('BAD SALAD MATCH')\n",
    "#             return ''\n",
    "#         else:\n",
    "# #             print('GOOD SALAD MATCH', salad_match)\n",
    "# #             print('NAME', name)\n",
    "# #             print('TERM', term)\n",
    "# #             print()\n",
    "#             return salad_match\n",
    "    \n",
    "#     name_tokens = [token.lower() for token in get_tokens(name)]  \n",
    "#     term_tokens_mixed = get_tokens(term)\n",
    "#     term_tokens = [token.lower() for token in term_tokens_mixed]\n",
    "    \n",
    "#     primary_name = re.split('\\(|—|e\\.g\\.', name)[0].strip()\n",
    "#     primary_name_split = primary_name.split(', ')\n",
    "#     single_comma_primary_name = len(primary_name_split) == 2\n",
    "    \n",
    "# #     print()\n",
    "#     if 'e.g.' in term:\n",
    "#         if single_comma_primary_name:\n",
    "#             if name_tokens[0] == term_tokens[0]:\n",
    "#                 if name_tokens[1] in term_tokens: # specific name in e.g. term\n",
    "# #                     print('NAME TOKENS In TERM TOKENS')\n",
    "#                     term_i = term_tokens.index(name_tokens[1])\n",
    "#                     if term_tokens_mixed[term_i] == term_tokens_mixed[term_i].upper():\n",
    "#                         match = 'D'\n",
    "#                     else:\n",
    "#                         if term_tokens_mixed[0] == term_tokens_mixed[0].upper():\n",
    "#                             match = 'D'\n",
    "#                         else:\n",
    "#                             match = 'd'\n",
    "#                 else: # name matches only generic (pre e.g.) part of term\n",
    "#                     if term_tokens_mixed[0] == term_tokens_mixed[0].upper():\n",
    "#                         match = 'C'\n",
    "#                     else:\n",
    "#                         match = 'c'\n",
    "#             else:\n",
    "#                 match = ''\n",
    "#         else:\n",
    "#             if name_tokens[0] == term_tokens[0]: # name matches term before e.g.\n",
    "#                 if term_tokens_mixed[0] == term_tokens_mixed[0].upper():\n",
    "#                     match = 'C'\n",
    "#                 else:\n",
    "#                     match = 'c'\n",
    "#             elif name_tokens[0] in term_tokens[1:]: # name matches term after e.g.\n",
    "#                 term_i = term_tokens.index(name_tokens[0])\n",
    "#                 if term_tokens_mixed[term_i] == term_tokens_mixed[term_i].upper():\n",
    "#                     match = 'D'\n",
    "#                 else:\n",
    "#                     if term_tokens_mixed[0] == term_tokens_mixed[0].upper():\n",
    "#                         match = 'D'\n",
    "#                     else:\n",
    "#                         match = 'd'\n",
    "#             else:\n",
    "#                 match = ''\n",
    "#     else:\n",
    "#         if single_comma_primary_name:\n",
    "#             if ' '.join(primary_name_split).lower() in term.lower() or primary_name.lower() in term.lower(): # if primary_name is in term, any order\n",
    "#                 if term_tokens_mixed[0] == term_tokens_mixed[0].upper():\n",
    "#                     match = 'D'\n",
    "#                 else:\n",
    "#                     match = 'd'\n",
    "#             elif name_tokens[0] == term_tokens[0]: # if first part of primary name matches first token in term\n",
    "#                 if term_tokens_mixed[0] == term_tokens_mixed[0].upper():\n",
    "#                     match = 'C'\n",
    "#                 else:\n",
    "#                     match = 'c'\n",
    "#             else:\n",
    "#                 match = ''\n",
    "#         else:\n",
    "#             if name_tokens[0] in term_tokens: # if non-comma name anywhere in non-e.g. term_tokens\n",
    "#                 if term_tokens_mixed[0] == term_tokens_mixed[0].upper():\n",
    "#                     match = 'D'\n",
    "#                 else:\n",
    "#                     match = 'd'\n",
    "#             elif len(set(name_tokens).intersection(set(term_tokens))) > 0: # if there are any common tokens\n",
    "#                 if term_tokens_mixed[0] == term_tokens_mixed[0].upper():\n",
    "#                     match = 'C'\n",
    "#                 else:\n",
    "#                     match = 'c'\n",
    "#             else:\n",
    "#                 match = ''\n",
    "                \n",
    "#     if match == '':\n",
    "#         n_common = len(set(name_tokens).intersection(set(term_tokens)))\n",
    "#         if n_common != 0:\n",
    "#             match = n_common\n",
    "#     return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # doing it this way so I can add 'print' to monitor progress\n",
    "# mark_data = []\n",
    "# for name in stir_fry_data['name']:\n",
    "#     print(name)\n",
    "#     mark_data.append([get_mark(name, term) for term in all_terms])\n",
    "\n",
    "# term_name_marks = pd.DataFrame(mark_data, columns = all_terms)\n",
    "# term_name_marks['name'] = pd.Series(stir_fry_data['name'].values.tolist())\n",
    "\n",
    "# term_name_marks.to_csv(os.path.join(root_path, 'DATA/stir_fry_term_name_marks.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extracting \"pairs with\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term_name_matches_raw = pd.read_csv(os.path.join(root_path, 'DATA/stir_fry_term_name_matches_plus.csv'))\n",
    "# term_name_matches = term_name_matches_raw.replace(['0', '1', '2', '3', '4', '5', 0, 1, 2, 3, 4, 5, float('nan')], '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CREATE PAIRING DATA MATRIX (names x names)\n",
    "# # takes a few minutes\n",
    "\n",
    "# pairing_data = pd.DataFrame({\n",
    "#     'name': stir_fry_data['name'],\n",
    "#     'pairs_with_terms': ingredient_pairs_with_terms\n",
    "# })\n",
    "\n",
    "# for name in stir_fry_data['name']:\n",
    "#     pairing_data[name] = pd.Series(['']*len(stir_fry_data['name']))\n",
    "\n",
    "# def get_pairs_with_names(row):\n",
    "#     lower_category_names = []\n",
    "#     lower_direct_names = []\n",
    "#     upper_category_names = []\n",
    "#     upper_direct_names = []\n",
    "#     for term in row['pairs_with_terms']:\n",
    "#         if term in term_name_matches.columns.values.tolist():\n",
    "#             lower_category_names += term_name_matches[term_name_matches[term] == 'c']['name'].values.tolist()\n",
    "#             lower_direct_names += term_name_matches[term_name_matches[term] == 'd']['name'].values.tolist()\n",
    "#             upper_category_names += term_name_matches[term_name_matches[term] == 'C']['name'].values.tolist()\n",
    "#             upper_direct_names += term_name_matches[term_name_matches[term] == 'D']['name'].values.tolist()\n",
    "#         else:\n",
    "#             pass\n",
    "#             print(term)\n",
    "    \n",
    "#     for lower_category_name in lower_category_names:\n",
    "#         row[lower_category_name] = 'c'\n",
    "#     for lower_direct_name in lower_direct_names:\n",
    "#         row[lower_direct_name] = 'd'\n",
    "#     for upper_category_name in upper_category_names:\n",
    "#         row[upper_category_name] = 'C'\n",
    "#     for upper_direct_name in upper_direct_names:\n",
    "#         row[upper_direct_name] = 'D'\n",
    "\n",
    "#     return row\n",
    "\n",
    "# pairing_data = pairing_data.apply(get_pairs_with_names, axis=1)\n",
    "# pairing_data.replace(float('nan'), '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SYNC PAIRING DATA MATRIX (make sure [a][b] agrees with [b][a])\n",
    "\n",
    "# for index_1, name_1 in enumerate(pairing_data['name'].values.tolist()):\n",
    "#     for index_2, name_2 in enumerate(pairing_data['name'].values.tolist()):\n",
    "#         value_1 = pairing_data[name_1][index_2]\n",
    "#         value_2 = pairing_data[name_2][index_1]\n",
    "        \n",
    "#         if name_1 == name_2:\n",
    "#             proper_value = ''\n",
    "#         elif value_1 == 'D' or value_2 == 'D':\n",
    "#             proper_value = 'D'\n",
    "#         elif value_1 == 'C' or value_2 == 'C':\n",
    "#             proper_value = 'C'\n",
    "#         elif value_1 == 'd' or value_2 == 'd':\n",
    "#             proper_value = 'd'\n",
    "#         elif value_1 == 'c' or value_2 == 'c':\n",
    "#             proper_value = 'c'\n",
    "#         else:\n",
    "#             proper_value = ''\n",
    "        \n",
    "#         pairing_data[name_1][index_2] = proper_value\n",
    "#         pairing_data[name_2][index_1] = proper_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # REPRESENT PAIRING DATA AS LISTS\n",
    "\n",
    "# def get_pairs_with_names(row):\n",
    "#     lower_category_name = pairing_data[pairing_data[row['name']] == 'c']['name'].values.tolist()\n",
    "#     lower_direct_name = pairing_data[pairing_data[row['name']] == 'd']['name'].values.tolist()\n",
    "#     upper_category_name = pairing_data[pairing_data[row['name']] == 'C']['name'].values.tolist()\n",
    "#     upper_direct_name = pairing_data[pairing_data[row['name']] == 'D']['name'].values.tolist()\n",
    "    \n",
    "#     row['lower_category_names'] = pairing_data[pairing_data[row['name']] == 'c']['name'].values.tolist()\n",
    "#     row['lower_direct_names'] = pairing_data[pairing_data[row['name']] == 'd']['name'].values.tolist()\n",
    "#     row['upper_category_names'] = pairing_data[pairing_data[row['name']] == 'C']['name'].values.tolist()\n",
    "#     row['upper_direct_names'] = pairing_data[pairing_data[row['name']] == 'D']['name'].values.tolist()\n",
    "#     row['lower_names'] = row['lower_category_names'] + row['lower_direct_names']\n",
    "#     row['upper_names'] = row['upper_category_names'] + row['upper_direct_names']\n",
    "#     row['all_names'] = row['lower_names'] + row['upper_names']\n",
    "    \n",
    "# #     row['lower_category_pairs_with_names'] = list(set([lower_category_name for lower_category_name in row['lower_category_names'] if lower_category_name != row['name']]))\n",
    "# #     row['lower_direct_pairs_with_names'] = list(set([lower_direct_name for lower_direct_name in row['lower_direct_names'] if lower_direct_name != row['name']]))\n",
    "# #     row['upper_category_pairs_with_names'] = list(set([upper_category_name for upper_category_name in row['upper_category_names'] if upper_category_name != row['name']]))\n",
    "# #     row['upper_direct_pairs_with_names'] = list(set([upper_direct_name for upper_direct_name in row['upper_direct_names'] if upper_direct_name != row['name']]))\n",
    "# #     row['lower_pairs_with_names'] = list(set(row['lower_category_pairs_with_names'] + row['lower_direct_pairs_with_names']))\n",
    "# #     row['upper_pairs_with_names'] = list(set(row['upper_category_pairs_with_names'] + row['upper_direct_pairs_with_names']))\n",
    "# #     row['all_pairs_with_names'] = list(set(row['lower_pairs_with_names'] + row['upper_pairs_with_names']))\n",
    "    \n",
    "#     row['lc_sorted_pairs'] = [tuple(sorted((row['name'], other_name,))) for other_name in row['lower_category_names']]\n",
    "#     row['ld_sorted_pairs'] = [tuple(sorted((row['name'], other_name,))) for other_name in row['lower_direct_names']]\n",
    "#     row['uc_sorted_pairs'] = [tuple(sorted((row['name'], other_name,))) for other_name in row['upper_category_names']]\n",
    "#     row['ud_sorted_pairs'] = [tuple(sorted((row['name'], other_name,))) for other_name in row['upper_direct_names']]\n",
    "#     row['l_sorted_pairs'] = [tuple(sorted((row['name'], other_name,))) for other_name in row['lower_names']]\n",
    "#     row['u_sorted_pairs'] = [tuple(sorted((row['name'], other_name,))) for other_name in row['upper_names']]\n",
    "#     row['a_sorted_pairs'] = [tuple(sorted((row['name'], other_name,))) for other_name in row['all_names']]\n",
    "    \n",
    "#     return row\n",
    "\n",
    "# pairing_data = pairing_data.apply(get_pairs_with_names, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairing_data.to_pickle(os.path.join(root_path, 'DATA/pairing_data.pickle'))\n",
    "pairing_data = pd.read_pickle(os.path.join(root_path, 'DATA/pairing_data.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating \"clashes with\" data \\[gonna start out without this one, for stir fry\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_name_clashes_blank = stir_fry_data[['name', 'protein_cheese_sub', 'stir_fry_allium', 'fruit', 'veg']].copy()\n",
    "# names = stir_fry_data['name'].values.tolist()\n",
    "\n",
    "# for i, col_name in enumerate(names):\n",
    "#     name_name_clashes_blank[col_name] = pd.Series(['x']*(i+1) + ['']*(len(names)-(i+1)))\n",
    "\n",
    "# name_name_clashes_blank.to_csv(os.path.join(root_path, 'DATA/name_name_clashes_blank.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_name_clashes_input = pd.read_csv(os.path.join(root_path, 'DATA/name_name_clashes_input.csv'))\n",
    "# name_name_clashes_input = name_name_clashes_input.replace([float('nan'), 'x'], '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['name'] + name_name_clashes_input['name'].values.tolist()\n",
    "# name_name_clashes_input = name_name_clashes_input[columns]\n",
    "\n",
    "# def get_clashes_with_data(row):\n",
    "#     data = pd.Series([])\n",
    "#     name = row['name']\n",
    "#     data['name'] = name\n",
    "    \n",
    "#     lower_names = name_name_clashes_input['name'][name_name_clashes_input[name] == 'y'].values.tolist()\n",
    "#     upper_names = name_name_clashes_input['name'][name_name_clashes_input[name] == 'Y'].values.tolist()\n",
    "#     if 'y' in lower_names:\n",
    "#         print(lower_names)\n",
    "    \n",
    "#     for name in name_name_clashes_input['name']:\n",
    "#         if row[name] == 'y':\n",
    "#             lower_names.append(name)\n",
    "#         elif row[name] == 'Y':\n",
    "#             upper_names.append(name)\n",
    "    \n",
    "#     lower_names = list(set(lower_names))\n",
    "#     upper_names = list(set(upper_names))\n",
    "    \n",
    "#     data['lower_clashes_with_names'] = lower_names\n",
    "#     data['upper_clashes_with_names'] = upper_names\n",
    "#     data['all_clashes_with_names'] = list(set(lower_names + upper_names)) # shouldn't be overlap here, but hey\n",
    "    \n",
    "#     data['lower_clashes_with_pairs'] = [tuple(sorted([name, lower_name])) for lower_name in data['lower_clashes_with_names']]\n",
    "#     data['upper_clashes_with_pairs'] = [tuple(sorted([name, lower_name])) for lower_name in data['upper_clashes_with_names']]\n",
    "#     data['all_clashes_with_pairs'] = [tuple(sorted([name, lower_name])) for lower_name in data['all_clashes_with_names']]\n",
    "    \n",
    "#     return data\n",
    "\n",
    "# clashes_with_data = name_name_clashes_input.apply(get_clashes_with_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SYNC PAIRING DATA MATRIX (make sure [a][b] agrees with [b][a])\n",
    "\n",
    "# name_name_clashes_synced = name_name_clashes_input.copy()\n",
    "\n",
    "# for index_1, name_1 in enumerate(name_name_clashes_input['name'].values.tolist()):\n",
    "#     for index_2, name_2 in enumerate(name_name_clashes_input['name'].values.tolist()):\n",
    "#         value_1 = name_name_clashes_input[name_1][index_2]\n",
    "#         value_2 = name_name_clashes_input[name_2][index_1]\n",
    "        \n",
    "#         if name_1 == name_2:\n",
    "#             proper_value = ''\n",
    "#         elif value_1 == 'Y' or value_2 == 'Y':\n",
    "#             proper_value = 'Y'\n",
    "#         elif value_1 == 'y' or value_2 == 'y':\n",
    "#             proper_value = 'y'\n",
    "#         else:\n",
    "#             proper_value = ''\n",
    "        \n",
    "#         name_name_clashes_synced[name_1][index_2] = proper_value\n",
    "#         name_name_clashes_synced[name_2][index_1] = proper_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add name_name_clashes_synced to clashes_with_data\n",
    "# clashes_with_data[name_name_clashes_synced['name'].tolist()] = name_name_clashes_synced[name_name_clashes_synced['name'].tolist()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clashes_with_data.to_pickle(os.path.join(root_path, 'DATA/clashes_with_data.pickle'))\n",
    "# clashes_with_data = pd.read_pickle(os.path.join(root_path, 'DATA/clashes_with_data.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Creating connection data \\[without clashes data, for now\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/russell/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/russell/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# CREATING CONNECTION DATA AND ADDING IT TO stir_fry DATA (& getting stir_fry_data in order)\n",
    "# takes a minute\n",
    "stir_fry_names = stir_fry_data['name'].values.tolist()\n",
    "for col_name in stir_fry_names:\n",
    "    col_values = []\n",
    "    for row_name in stir_fry_names:\n",
    "        pairing_value = pairing_data[col_name][pairing_data['name'] == row_name].iloc[0]\n",
    "#         clashing_value = clashes_with_data[col_name][clashes_with_data['name'] == row_name].iloc[0]\n",
    "\n",
    "#         if clashing_value == 'Y':\n",
    "#             col_values.append('N')\n",
    "#         elif clashing_value == 'y':\n",
    "#             col_values.append('n')\n",
    "#         elif pairing_value == 'D':\n",
    "#             col_values.append('D')\n",
    "#         elif pairing_value == 'C':\n",
    "#             col_values.append('C')\n",
    "#         elif pairing_value == 'd':\n",
    "#             col_values.append('d')\n",
    "#         elif pairing_value == 'c':\n",
    "#             col_values.append('c')\n",
    "#         else:\n",
    "#             col_values.append('')\n",
    "        col_values.append(pairing_value)\n",
    "\n",
    "    stir_fry_data[col_name] = pd.Series(col_values)\n",
    "    \n",
    "# just in case\n",
    "stir_fry_data.sort_values('name', inplace=True)\n",
    "stir_fry_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stir_fry_data.to_pickle(os.path.join(root_path, 'DATA/stir_fry_data_with_names.pickle'))\n",
    "stir_fry_data = pd.read_pickle(os.path.join(root_path, 'DATA/stir_fry_data_with_names.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Creating flavor tool data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "stir_fry_flavor_data = stir_fry_data[['staple', 'not_vegan', 'gluten', 'flavoring_sweet', 'flavoring_fresh', 'flavoring_wet', 'flavoring_concentrate', 'flavoring', 'flavoring_dry', 'protein', 'protein_cheese_sub', 'protein_milk_sub', 'protein_meat_sub', 'protein_bean', 'veg', 'veg_leafy', 'grain', 'grain_flour', 'fat_oil', 'oil', 'fat', 'fruit', 'fruit_berry', 'stir_fry', 'stir_fry_basic', 'stir_fry_yes', 'stir_fry_early', 'stir_fry_mid', 'stir_fry_late', 'stir_fry_garnish', 'stir_fry_umbrella', 'protein_nut_seed', 'protein_nut', 'protein_seed', 'redirect', 'salty', 'sour', 'spicy', 'bitter', 'savory', 'sweet','name', 'flavor', 'volume', 'pairs_with', 'phonetic', 'techniques', 'dishes', 'tip', 'possible_substitutes', 'flavor_affinities', 'nutritional_profile', 'season', 'botanical_relatives', 'protein_content', 'what_they_are', 'brands', 'vegan_substitutes', 'vegan_brands', 'stir_fry_protein', 'stir_fry_protein_nut_seed', 'stir_fry_protein_nut', 'stir_fry_protein_seed', 'stir_fry_flavoring', 'stir_fry_oil', 'stir_fry_fat', 'stir_fry_fat_oil', 'stir_fry_fruit', 'stir_fry_allium', 'stir_fry_protein_bean', 'stir_fry_veg', 'stir_fry_grain', 'stir_fry_salt', 'stir_fry_pepper', 'stir_fry_vinegar'] + stir_fry_data['name'].tolist()].copy()\n",
    "stir_fry_flavor_data['id'] = stir_fry_data.index\n",
    "\n",
    "selected_pairing_data = pairing_data[['name', 'pairs_with_terms', 'lower_category_names', 'lower_direct_names', 'upper_category_names', 'upper_direct_names', 'lower_names', 'upper_names', 'all_names', 'lc_sorted_pairs', 'ld_sorted_pairs', 'uc_sorted_pairs', 'ud_sorted_pairs', 'l_sorted_pairs', 'u_sorted_pairs', 'a_sorted_pairs']]\n",
    "stir_fry_flavor_data = stir_fry_flavor_data.merge(selected_pairing_data, how='inner', on='name')\n",
    "\n",
    "# selected_clashes_with_data = clashes_with_data[['name', 'lower_clashes_with_names', 'upper_clashes_with_names', 'all_clashes_with_names', 'lower_clashes_with_pairs', 'upper_clashes_with_pairs', 'all_clashes_with_pairs']]\n",
    "# stir_fry_flavor_data = stir_fry_flavor_data.merge(selected_clashes_with_data, how='inner', on='name')\n",
    "\n",
    "# just in case\n",
    "stir_fry_flavor_data = stir_fry_flavor_data.replace(float('nan'), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stir_fry_flavor_data.to_pickle(os.path.join(root_path, 'DATA/stir_fry_flavor_data.pickle'))\n",
    "# stir_fry_flavor_data.to_pickle(os.path.join(root_path, '../data/stir_fry_flavor_data.pickle'))\n",
    "stir_fry_flavor_data = pd.read_pickle(os.path.join(root_path, 'DATA/stir_fry_flavor_data.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. stir_fry recipe generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Flavor tool generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install networkx==2.4\n",
    "# !pip install pyvis\n",
    "\n",
    "import networkx as nx\n",
    "from pyvis import network as net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE PLAN\n",
    "    # is to let 'flavor balance bonus' take care of salt, vinegar, fruit etc. selection\n",
    "    # the only exception is 1 picked salt in every dish. salt also appears in flavorings, so I'll discourage doubling but not forbid it.\n",
    "\n",
    "    # Not gonna worry about balancing food groups too much.\n",
    "        # factor for protein balance? (YES, THIS)\n",
    "        # or selected protein? (0-3?)\n",
    "            # but without food group balance OR texture balance, only regulator would be pairs w\n",
    "    # oh! and maybe a hard limit on flavorings?\n",
    "        # or a bonus.. but that'd reward a lot, and I really only want a few flavorings per dish? (and for sure a few flavorings)\n",
    "        # HARD LIMIT IT IS\n",
    "            # but I think I'll draw from other_flavorings after all, if flavorings and salt are the only other distinct groups\n",
    "     # and I think fat/oil, like salt, is one of those things where you gotta add a certain amt, but if there's a lot you can just add a little\n",
    "        # so that's a distinct category, then\n",
    "        \n",
    "# UNKNOWNS\n",
    "    # 7 or 8 max? and will I need to reward balance?\n",
    "    # special allium category? or just reward alliums? or just onions?\n",
    "    \n",
    "n_locked = random.randrange(0, 1)\n",
    "locked = stir_fry_data.sample(n_locked)\n",
    "# locked_proteins = locked[locked['protein'] == 'y']\n",
    "# locked_protein_nut_seeds = locked[locked['stir_fry_protein_nut_seed'] == 'y']\n",
    "# locked_protein_nuts = locked[locked['stir_fry_protein_nut'] == 'y']\n",
    "# locked_protein_seeds = locked[locked['stir_fry_protein_seed'] == 'y']\n",
    "# locked_alliums = locked[locked['stir_fry_allium'] == 'y']\n",
    "# locked_flavorings = locked[locked['stir_fry_flavoring'] == 'y']\n",
    "locked_fat_oils = locked[locked['stir_fry_fat_oil'] == 'y']\n",
    "# locked_fats = locked[locked['stir_fry_fat'] == 'y']\n",
    "# locked_oils = locked[locked['stir_fry_oil'] == 'y']\n",
    "# locked_fruits = locked[locked['stir_fry_fruit'] == 'y']\n",
    "# locked_protein_beans = locked[locked['stir_fry_protein_bean'] == 'y']\n",
    "# locked_veg = locked[locked['stir_fry_veg'] == 'y']\n",
    "# locked_grains = locked[locked['stir_fry_grain'] == 'y']\n",
    "locked_salts = locked[locked['stir_fry_salt'] == 'y']\n",
    "# locked_peppers = locked[locked['stir_fry_pepper'] == 'y']\n",
    "# locked_vinegars = locked[locked['stir_fry_vinegar'] == 'y']\n",
    "locked_other_flavorings = locked[(locked['stir_fry_flavoring'] == 'y') & (locked['stir_fry_salt'] != 'y')]\n",
    "locked_foodstuffs = locked[(locked['stir_fry_fat_oil'] != 'y') & (locked['stir_fry_salt'] != 'y') & (locked['stir_fry_flavoring'] != 'y')]\n",
    "\n",
    "the_rest = stir_fry_data[~stir_fry_data['name'].isin(locked['name'])]\n",
    "# the_rest_proteins = the_rest[the_rest['protein'] == 'y']\n",
    "# the_rest_protein_nut_seeds = the_rest[the_rest['stir_fry_protein_nut_seed'] == 'y']\n",
    "# the_rest_protein_nuts = the_rest[the_rest['stir_fry_protein_nut'] == 'y']\n",
    "# the_rest_protein_seeds = the_rest[the_rest['stir_fry_protein_seed'] == 'y']\n",
    "# the_rest_alliums = the_rest[the_rest['stir_fry_allium'] == 'y']\n",
    "# the_rest_flavorings = the_rest[the_rest['stir_fry_flavoring'] == 'y']\n",
    "the_rest_fat_oils = the_rest[the_rest['stir_fry_fat_oil'] == 'y']\n",
    "# the_rest_fats = the_rest[the_rest['stir_fry_fat'] == 'y']\n",
    "# the_rest_oils = the_rest[the_rest['stir_fry_oil'] == 'y']\n",
    "# the_rest_fruits = the_rest[the_rest['stir_fry_fruit'] == 'y']\n",
    "# the_rest_protein_beans = the_rest[the_rest['stir_fry_protein_bean'] == 'y']\n",
    "# the_rest_veg = the_rest[the_rest['stir_fry_veg'] == 'y']\n",
    "# the_rest_grains = the_rest[the_rest['stir_fry_grain'] == 'y']\n",
    "the_rest_salts = the_rest[the_rest['stir_fry_salt'] == 'y']\n",
    "# the_rest_peppers = the_rest[the_rest['stir_fry_pepper'] == 'y']\n",
    "# the_rest_vinegars = the_rest[the_rest['stir_fry_vinegar'] == 'y']\n",
    "the_rest_other_flavorings = the_rest[(the_rest['stir_fry_flavoring'] == 'y') & (the_rest['stir_fry_salt'] != 'y')]\n",
    "the_rest_foodstuffs = the_rest[(the_rest['stir_fry_fat_oil'] != 'y') & (the_rest['stir_fry_salt'] != 'y') & (the_rest['stir_fry_flavoring'] != 'y')]\n",
    "\n",
    "n_gen_salts = max(1 - len(locked_salts), 0)\n",
    "n_gen_fat_oils = max(1 - len(locked_fat_oils), 0)\n",
    "n_gen_other_flavorings_min = max(1 - len(locked_other_flavorings), 0)\n",
    "n_gen_other_flavorings_max = max(3 - len(locked_other_flavorings), 0)\n",
    "n_gen_foodstuffs_min = max(3 - len(locked_foodstuffs), 0)\n",
    "n_gen_foodstuffs_max = max(7 - len(locked_foodstuffs), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW AVG SHORTEST PATH SCORE 1.5396825396825395\n",
      "N FOODSTUFFS 6\n",
      "TOTAL SCORE 4.914266742553594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"500px\"\n",
       "            height=\"500px\"\n",
       "            src=\"top_net.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f96fa5b45c0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# account for if connected subgraph is impossible\n",
    "# naming conventions (e.g. for clashing, pairing pairs) kinda wonky\n",
    "\n",
    "top_score = 0\n",
    "for try_i in range(100):\n",
    "    n_subgraphs = 2\n",
    "    while n_subgraphs > 1: # keep shuffling until you get a well connected graph\n",
    "        n_gen_other_flavorings = min(random.randrange(n_gen_other_flavorings_min, n_gen_other_flavorings_max+1), len(the_rest_other_flavorings))\n",
    "        n_gen_foodstuffs = min(random.randrange(n_gen_foodstuffs_min, n_gen_foodstuffs_max+1), len(the_rest_foodstuffs))\n",
    "        \n",
    "        selected_salts = locked_salts.append(the_rest_salts.sample(n_gen_salts))\n",
    "        selected_fat_oils = locked_fat_oils.append(the_rest_fat_oils.sample(n_gen_fat_oils))\n",
    "        selected_other_flavorings = locked_other_flavorings.append(the_rest_other_flavorings.sample(n_gen_other_flavorings))\n",
    "        selected_foodstuffs = locked_foodstuffs.append(the_rest_foodstuffs.sample(n_gen_foodstuffs))\n",
    "        selected_ingredients = selected_salts.append(selected_fat_oils).append(selected_other_flavorings).append(selected_foodstuffs)\n",
    "        selected_names = selected_ingredients['name'].values.tolist()\n",
    "\n",
    "        lower_category_pairs = []\n",
    "        lower_direct_pairs = []\n",
    "        upper_category_pairs = []\n",
    "        upper_direct_pairs = []\n",
    "#         lower_clashing_pairs = []\n",
    "#         upper_clashing_pairs = []\n",
    "\n",
    "        # finicky but pretty fast\n",
    "        for i, col_name in enumerate(selected_names):\n",
    "            for j, row_name in enumerate(selected_names[i+1:]):\n",
    "                connection = selected_ingredients[col_name].tolist()[i+1+j] # this is what is finicky\n",
    "#                 print('CONNECTION', connection)\n",
    "                if connection == 'c':\n",
    "                    lower_category_pairs.append((col_name, row_name,))\n",
    "                elif connection == 'd':\n",
    "                    lower_direct_pairs.append((col_name, row_name,))\n",
    "                elif connection == 'C':\n",
    "                    upper_category_pairs.append((col_name, row_name,))\n",
    "                elif connection == 'D':\n",
    "                    upper_direct_pairs.append((col_name, row_name,))\n",
    "#                 elif connection == 'n':\n",
    "#                     lower_clashing_pairs.append((col_name, row_name,))\n",
    "#                 elif connection == 'N':\n",
    "#                     upper_clashing_pairs.append((col_name, row_name,))\n",
    "        lower_pairs = lower_category_pairs + lower_direct_pairs\n",
    "        upper_pairs = upper_category_pairs + upper_direct_pairs\n",
    "        all_pairs = lower_pairs + upper_pairs\n",
    "#         all_clashing_pairs = lower_clashing_pairs + upper_clashing_pairs\n",
    "#         print(len(all_pairs))\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(selected_names)\n",
    "        G.add_edges_from(lower_category_pairs, length=2)\n",
    "        G.add_edges_from(lower_direct_pairs, length=1.5)\n",
    "        G.add_edges_from(upper_category_pairs, length=1.2)\n",
    "        G.add_edges_from(upper_direct_pairs, length=1)\n",
    "        n_subgraphs = len(list(nx.connected_component_subgraphs(G)))\n",
    "#         print(n_subgraphs)\n",
    "#         print()\n",
    "    score = 0\n",
    "\n",
    "# PAIRING BONUS ============================================================================================\n",
    "# ranges from roughly (0 to 1) * 3, tho could be a lil over or under that range\n",
    "    average_shortest_path_length = nx.average_shortest_path_length(G, weight='length')\n",
    "    average_shortest_path_score = 1 / average_shortest_path_length * 4 - 1\n",
    "    score += average_shortest_path_score * 3\n",
    "\n",
    "# # important but easy to avoid, so not weighted too heavily\n",
    "# # CLASH PENALTY ====================================================================================================\n",
    "# # ranges from roughly (0 to 1) * -1.5\n",
    "#     clashing_pairs_score = len(all_clashing_pairs)\n",
    "#     score += clashing_pairs_score * -1.5\n",
    "\n",
    "# FLAVOR BALANCE BONUS =============================================================================================\n",
    "# ranges from roughly (0 to 1) * 1 (could be a lil over/under)\n",
    "    n_sweet_lower = (selected_ingredients['sweet'] == 'y').sum()\n",
    "    n_sweet_upper = (selected_ingredients['sweet'] == 'Y').sum()\n",
    "    n_salty_lower = (selected_ingredients['salty'] == 'y').sum()\n",
    "    n_salty_upper = (selected_ingredients['salty'] == 'Y').sum()\n",
    "    n_sour_lower = (selected_ingredients['sour'] == 'y').sum()\n",
    "    n_sour_upper = (selected_ingredients['sour'] == 'Y').sum()\n",
    "    n_savory_lower = (selected_ingredients['savory'] == 'y').sum()\n",
    "    n_savory_upper = (selected_ingredients['savory'] == 'Y').sum()\n",
    "    n_bitter_lower = (selected_ingredients['bitter'] == 'y').sum()\n",
    "    n_bitter_upper = (selected_ingredients['bitter'] == 'Y').sum()\n",
    "    n_spicy_lower = (selected_ingredients['spicy'] == 'y').sum()\n",
    "    n_spicy_upper = (selected_ingredients['spicy'] == 'Y').sum()\n",
    "\n",
    "    # each varies from roughly .5 to 1 (normalized to the average flavor score)\n",
    "    sweet_score = (n_sweet_lower/2 + n_sweet_upper)/6\n",
    "    salty_score = (n_salty_lower/2 + n_salty_upper)/4\n",
    "    sour_score = (n_sour_lower/2 + n_sour_upper)/2.5\n",
    "    savory_score = (n_savory_lower/2 + n_savory_upper)/3\n",
    "    bitter_score = (n_bitter_lower/2 + n_bitter_upper)/3\n",
    "    spicy_score = (n_spicy_lower/2 + n_spicy_upper)/3\n",
    "#     print(sweet_score, salty_score, sour_score, savory_score, bitter_score, spicy_score)\n",
    "\n",
    "    flavor_balance_score = 5 / (1 + abs(1-sweet_score) + abs(1-salty_score) + abs(1-sour_score) + abs(1-savory_score) + abs(1-spicy_score)) - .9\n",
    "#     print(flavor_balance_score)\n",
    "    score += flavor_balance_score\n",
    "\n",
    "# # TEXTURE BALANCE BONUS ============================================================================================\n",
    "# # ranges from roughly (0 to 1) * .75\n",
    "#     n_crunchy_lower = (selected_ingredients['stir_fry_crunchy'] == 'y').sum()\n",
    "#     n_crunchy_upper = (selected_ingredients['stir_fry_crunchy'] == 'Y').sum()\n",
    "#     n_chewy_lower = (selected_ingredients['stir_fry_chewy'] == 'y').sum()\n",
    "#     n_chewy_upper = (selected_ingredients['stir_fry_chewy'] == 'Y').sum()\n",
    "#     n_juicy_lower = (selected_ingredients['stir_fry_juicy'] == 'y').sum()\n",
    "#     n_juicy_upper = (selected_ingredients['stir_fry_juicy'] == 'Y').sum()\n",
    "\n",
    "#     # each ranges from roughly 0 to 1\n",
    "#     crunchy_score = (n_crunchy_lower/2 + n_crunchy_upper)/3\n",
    "#     chewy_score = (n_chewy_lower/2 + n_chewy_upper)\n",
    "#     juicy_score = (n_juicy_lower/2 + n_juicy_upper)/3\n",
    "\n",
    "#     texture_balance_score = 5 / (1 + abs(1-crunchy_score) + abs(1-chewy_score) + abs(1-juicy_score)) - 1.25\n",
    "#     score += texture_balance_score * .75\n",
    "\n",
    "# # will bias toward larger stir_frys, slightly\n",
    "# # seems like it's hard to balance food groups on top of everything else. pity the scores aren't more independent\n",
    "# # FOOD GROUP BALANCE BONUS =========================================================================================\n",
    "# # ranges from roughly (0 to 1) * 2\n",
    "#     n_fruit = (selected_ingredients['fruit'] == 'y').sum()\n",
    "#     n_veg = (selected_ingredients['veg'] == 'y').sum()\n",
    "#     n_protein = (selected_ingredients['protein'] == 'y').sum()\n",
    "    \n",
    "#     # /2 for steep diminishing returns (?)\n",
    "#     fruit_score = (n_fruit/2)**.5\n",
    "#     veg_score = (n_veg/2)**.5\n",
    "#     protein_score = (n_protein/2)**.5 #(0->0, 1->1, 4->2, 9->3)\n",
    "#     food_group_balance_score = (3*fruit_score + veg_score + 2*protein_score) * .22 - .33\n",
    "#     score += food_group_balance_score * 2\n",
    "    \n",
    "    if score > top_score:\n",
    "        top_score = score\n",
    "#         top_food_group_balance_score = food_group_balance_score\n",
    "#         top_flavor_balance_score = flavor_balance_score\n",
    "#         top_texture_balance_score = texture_balance_score\n",
    "#         top_clashing_pairs_score = clashing_pairs_score\n",
    "        top_lc_pairs = lower_category_pairs\n",
    "        top_ld_pairs = lower_direct_pairs\n",
    "        top_uc_pairs = upper_category_pairs\n",
    "        top_ud_pairs = upper_direct_pairs\n",
    "        top_selected_ingredients = selected_ingredients\n",
    "        top_average_shortest_path_score = average_shortest_path_score\n",
    "\n",
    "print('RAW AVG SHORTEST PATH SCORE', top_average_shortest_path_score)\n",
    "# print('RAW CLASHING PAIRS SCORE', top_clashing_pairs_score)\n",
    "# print('RAW FLAVOR BALANCE SCORE', top_flavor_balance_score)\n",
    "# print('RAW TEXTURE BALANCE SCORE', top_texture_balance_score)\n",
    "# print('RAW FOOD GROUP BALANCE SCORE', top_food_group_balance_score)\n",
    "print('N FOODSTUFFS', n_gen_foodstuffs)\n",
    "print('TOTAL SCORE', top_score)         \n",
    "\n",
    "top_net = net.Network(notebook=True)\n",
    "\n",
    "nodes = top_selected_ingredients['name'].tolist()\n",
    "\n",
    "def get_color(row):\n",
    "#     return 'grey'\n",
    "    if row['stir_fry_veg'] == 'y':\n",
    "        return 'green'\n",
    "    elif row['stir_fry_fruit'] == 'y':\n",
    "        return 'orange'\n",
    "    elif row['stir_fry_protein'] == 'y':\n",
    "        return 'brown'\n",
    "    elif row['stir_fry_fat_oil'] == 'y':\n",
    "        return 'tan'\n",
    "    elif row['stir_fry_salt'] == 'y':\n",
    "        return 'whitesmoke'\n",
    "    elif row['stir_fry_flavoring'] == 'y':\n",
    "        return 'darkgrey'\n",
    "    else:\n",
    "        return 'grey'\n",
    "#     if row['stir_fry_green'] == 'y':\n",
    "#         return 'lightgreen'\n",
    "#     elif row['stir_fry_extra'] == 'y':\n",
    "#         if row['veg'] == 'y':\n",
    "#             return 'green'\n",
    "#         elif row['fruit'] == 'y':\n",
    "#             return 'orange'\n",
    "#         elif row['protein_nut_seed'] == 'y':\n",
    "#             return 'brown'\n",
    "#         else:\n",
    "#             return 'lightblue'\n",
    "#     elif row['stir_fry_dressing'] == 'y':\n",
    "#         return 'lightgrey'\n",
    "nodes_color = top_selected_ingredients.apply(get_color, axis=1).tolist()\n",
    "\n",
    "top_net.add_nodes(\n",
    "    nodes=nodes,\n",
    "    color=nodes_color\n",
    ")\n",
    "\n",
    "for pair in top_lc_pairs:\n",
    "    top_net.add_edge(pair[0], pair[1], physics=False, color='lightgrey')\n",
    "for pair in top_ld_pairs:\n",
    "    top_net.add_edge(pair[0], pair[1], physics=False, color='grey')\n",
    "for pair in top_uc_pairs:\n",
    "    top_net.add_edge(pair[0], pair[1], color='darkgrey')\n",
    "for pair in top_ud_pairs:\n",
    "    top_net.add_edge(pair[0], pair[1], color='black')\n",
    "\n",
    "# vegan = top_selected_ingredients['not_vegan'].sum() == ''\n",
    "# gluten_free = top_selected_ingredients['gluten'].sum() == ''\n",
    "\n",
    "top_net.show('top_net.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Random control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"500px\"\n",
       "            height=\"500px\"\n",
       "            src=\"random_net.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f396b4e84a8>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_subgraphs = 2\n",
    "while n_subgraphs > 1: # keep shuffling until you get a well connected graph\n",
    "\n",
    "    n_gen_greens = random.randrange(n_gen_greens_min, n_gen_greens_max+1)\n",
    "\n",
    "    n_gen_extras = random.randrange(n_gen_extras_min, n_gen_extras_max+1)\n",
    "\n",
    "    n_gen_dressing_oils = max(1-len(locked_dressing_oils), 0)\n",
    "    n_gen_dressing_vinegars = max(1-len(locked_dressing_vinegars), 0)\n",
    "    n_gen_dressing_salts = max(1-len(locked_dressing_salts), 0)\n",
    "    n_gen_dressing_peppers = max(1-len(locked_dressing_oils), 0)\n",
    "\n",
    "    selected_greens = locked_greens.append(the_rest_greens.sample(n_gen_greens))\n",
    "    selected_extras = locked_extras.append(the_rest_extras.sample(n_gen_extras))\n",
    "    selected_dressing_oils = locked_dressing_oils.append(the_rest_dressing_oils.sample(n_gen_dressing_oils))\n",
    "    selected_dressing_vinegars = locked_dressing_vinegars.append(the_rest_dressing_vinegars.sample(n_gen_dressing_vinegars))\n",
    "    selected_dressing_salts = locked_dressing_salts.append(the_rest_dressing_salts.sample(n_gen_dressing_salts))\n",
    "    selected_dressing_peppers = locked_dressing_peppers.append(the_rest_dressing_peppers.sample(n_gen_dressing_peppers))\n",
    "    selected_ingredients = selected_greens.append(selected_extras).append(selected_dressing_oils).append(selected_dressing_vinegars).append(selected_dressing_salts).append(selected_dressing_peppers)\n",
    "    selected_names = selected_ingredients['name'].values.tolist()\n",
    "\n",
    "    lower_category_pairs = []\n",
    "    lower_direct_pairs = []\n",
    "    upper_category_pairs = []\n",
    "    upper_direct_pairs = []\n",
    "    lower_clashing_pairs = []\n",
    "    upper_clashing_pairs = []\n",
    "\n",
    "    # finicky but pretty fast\n",
    "    for i, col_name in enumerate(selected_names):\n",
    "        for j, row_name in enumerate(selected_names[i+1:]):\n",
    "            connection = selected_ingredients[col_name].tolist()[i+1+j] # this is what is finicky\n",
    "            if connection == 'c':\n",
    "                lower_category_pairs.append((col_name, row_name,))\n",
    "            elif connection == 'd':\n",
    "                lower_direct_pairs.append((col_name, row_name,))\n",
    "            elif connection == 'C':\n",
    "                upper_category_pairs.append((col_name, row_name,))\n",
    "            elif connection == 'D':\n",
    "                upper_direct_pairs.append((col_name, row_name,))\n",
    "            elif connection == 'n':\n",
    "                lower_clashing_pairs.append((col_name, row_name,))\n",
    "            elif connection == 'N':\n",
    "                upper_clashing_pairs.append((col_name, row_name,))\n",
    "    lower_pairs = lower_category_pairs + lower_direct_pairs\n",
    "    upper_pairs = upper_category_pairs + upper_direct_pairs\n",
    "    all_pairs = lower_pairs + upper_pairs\n",
    "    all_clashing_pairs = lower_clashing_pairs + upper_clashing_pairs\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(selected_names)\n",
    "    G.add_edges_from(lower_category_pairs, length=2)\n",
    "    G.add_edges_from(lower_direct_pairs, length=1.5)\n",
    "    G.add_edges_from(upper_category_pairs, length=1.2)\n",
    "    G.add_edges_from(upper_direct_pairs, length=1)\n",
    "    n_subgraphs = len(list(nx.connected_component_subgraphs(G)))\n",
    "\n",
    "random_net = net.Network(notebook=True)\n",
    "\n",
    "nodes = selected_ingredients['name'].tolist()\n",
    "\n",
    "def get_color(row):\n",
    "    if row['stir_fry_green'] == 'y':\n",
    "        return 'lightgreen'\n",
    "    elif row['stir_fry_extra'] == 'y':\n",
    "        if row['veg'] == 'y':\n",
    "            return 'green'\n",
    "        elif row['fruit'] == 'y':\n",
    "            return 'orange'\n",
    "        elif row['protein_nut_seed'] == 'y':\n",
    "            return 'brown'\n",
    "        else:\n",
    "            return 'lightblue'\n",
    "    elif row['stir_fry_dressing'] == 'y':\n",
    "        return 'lightgrey'\n",
    "nodes_color = selected_ingredients.apply(get_color, axis=1).tolist()\n",
    "\n",
    "random_net.add_nodes(\n",
    "    nodes=nodes,\n",
    "    color=nodes_color\n",
    ")\n",
    "\n",
    "for pair in lower_category_pairs:\n",
    "    random_net.add_edge(pair[0], pair[1], physics=False, color='lightgrey')\n",
    "for pair in lower_direct_pairs:\n",
    "    random_net.add_edge(pair[0], pair[1], physics=False, color='grey')\n",
    "for pair in upper_category_pairs:\n",
    "    random_net.add_edge(pair[0], pair[1], color='darkgrey')\n",
    "for pair in upper_direct_pairs:\n",
    "    random_net.add_edge(pair[0], pair[1], color='black')\n",
    "\n",
    "vegan = selected_ingredients['not_vegan'].sum() == ''\n",
    "gluten_free = selected_ingredients['gluten'].sum() == ''\n",
    "\n",
    "random_net.show('random_net.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Recording recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Recording with flavor tool generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     stir_fry_recipe_data = pd.read_pickle(os.path.join(root_path, 'DATA/stir_fry_recipe_data_latest.pickle'))\n",
    "#     print('stir_fry RECIPE DATA IMPORT SUCCESSFUL')\n",
    "# except:\n",
    "#     stir_fry_recipe_data = pd.DataFrame({\n",
    "#         'vegan': [],\n",
    "#         'gluten_free': [],\n",
    "#         'basic': [],\n",
    "#         'best_of': [],\n",
    "#         'score': [],\n",
    "#         'pairing_density_bonus': [],\n",
    "#         'pair_strength_bonus': [],\n",
    "#         'clash_penalty': [],\n",
    "#         'flavor_balance_bonus': [],\n",
    "#         'texture_balance_bonus': [],\n",
    "#         'food_group_balance_bonus': [],\n",
    "#         'lc_pairs': [],\n",
    "#         'ld_pairs': [],\n",
    "#         'uc_pairs': [],\n",
    "#         'ud_pairs':[],\n",
    "#         'clashing_pairs': [],\n",
    "#         'ingredient_names': [],\n",
    "#         'leafy_green_names': [],\n",
    "#         'extra_names': [],\n",
    "#         'dressing_names': [],\n",
    "#     })\n",
    "#     print('IMPORT FAILED, CREATING NEW stir_fry RECIPE DATAFRAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stir_fry_greens = stir_fry_data[stir_fry_data['stir_fry_green'] == 'y']\n",
    "\n",
    "# stir_fry_extras = stir_fry_data[stir_fry_data['stir_fry_extra'] == 'y']\n",
    "# stir_fry_extra_veg = stir_fry_data[(stir_fry_data['veg'] == 'y') & (stir_fry_data['stir_fry_extra'] == 'y')]\n",
    "# stir_fry_extra_fruits = stir_fry_data[(stir_fry_data['fruit'] == 'y') & (stir_fry_data['stir_fry_extra'] == 'y')]\n",
    "# stir_fry_extra_nuts = stir_fry_data[(stir_fry_data['protein_seed'] == 'y') & (stir_fry_data['stir_fry_extra'] == 'y')]\n",
    "# stir_fry_extra_seeds = stir_fry_data[(stir_fry_data['protein_nut'] == 'y') & (stir_fry_data['stir_fry_extra'] == 'y')]\n",
    "# stir_fry_extra_tomatoes = stir_fry_data[stir_fry_data['stir_fry_extra_tomato'] == 'y']\n",
    "# stir_fry_extra_olives = stir_fry_data[stir_fry_data['stir_fry_extra_olive'] == 'y']\n",
    "# stir_fry_extra_cheeses = stir_fry_data[stir_fry_data['stir_fry_extra_cheese'] == 'y']\n",
    "# stir_fry_extra_eggs = stir_fry_data[stir_fry_data['stir_fry_extra_egg'] == 'y']\n",
    "# stir_fry_extra_croutons = stir_fry_data[stir_fry_data['stir_fry_extra_crouton'] == 'y']\n",
    "\n",
    "# stir_fry_dressing_oils = stir_fry_data[stir_fry_data['stir_fry_dressing_oil'] == 'y']\n",
    "# stir_fry_dressing_vinegars = stir_fry_data[stir_fry_data['stir_fry_dressing_vinegar'] == 'y']\n",
    "# stir_fry_dressing_salts = stir_fry_data[stir_fry_data['stir_fry_dressing_salt'] == 'y']\n",
    "# stir_fry_dressing_peppers = stir_fry_data[stir_fry_data['stir_fry_dressing_pepper'] == 'y']\n",
    "# stir_fry_dressing_garlics = stir_fry_data[stir_fry_data['stir_fry_dressing_garlic'] == 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install networkx\n",
    "\n",
    "# import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# best_of = 300\n",
    "# for recipe_count in range(500):\n",
    "#     top_score = 0\n",
    "#     for i in range(best_of):\n",
    "#         n_subgraphs = 2\n",
    "#         while n_subgraphs > 1: # keep shuffling until you get a well connected graph\n",
    "#             n_greens = random.randrange(2, 4)\n",
    "#             n_extras = random.randrange(2, 6)\n",
    "#             n_dressing_oils = 1\n",
    "#             n_dressing_vinegars = 1\n",
    "#             n_dressing_salts = 1\n",
    "#             n_dressing_peppers = 1\n",
    "#             # n_dressing_garlics = random.randrange(0, 2) # maybe make presence dependent on the rest. or, just leave out for now.\n",
    "\n",
    "#             selected_greens = stir_fry_greens.sample(n_greens)\n",
    "#             selected_extras = stir_fry_extras.sample(n_extras)\n",
    "#             selected_dressing_oils = stir_fry_dressing_oils.sample(n_dressing_oils)\n",
    "#             selected_dressing_vinegars = stir_fry_dressing_vinegars.sample(n_dressing_vinegars)\n",
    "#             selected_dressing_salts = stir_fry_dressing_salts.sample(n_dressing_salts)\n",
    "#             selected_dressing_peppers = stir_fry_dressing_peppers.sample(n_dressing_peppers)\n",
    "#             selected_ingredients = selected_greens.append(selected_extras).append(selected_dressing_oils).append(selected_dressing_vinegars).append(selected_dressing_salts).append(selected_dressing_peppers)\n",
    "\n",
    "#             lower_category_pairs = []\n",
    "#             lower_direct_pairs = []\n",
    "#             upper_category_pairs = []\n",
    "#             upper_direct_pairs = []\n",
    "#             ingredients_list = selected_ingredients['name'].values.tolist()\n",
    "#             already_checked = []\n",
    "#             for ingredient_name in ingredients_list:\n",
    "#                 for lc_name in pairing_data['lower_category_names'][pairing_data['name'] == ingredient_name].iloc[0]:\n",
    "#                     if lc_name in ingredients_list and not lc_name in already_checked:\n",
    "#                         lower_category_pairs.append([ingredient_name, lc_name])\n",
    "#                 for ld_name in pairing_data['lower_direct_names'][pairing_data['name'] == ingredient_name].iloc[0]:\n",
    "#                     if ld_name in ingredients_list and not ld_name in already_checked:\n",
    "#                         lower_direct_pairs.append([ingredient_name, ld_name])\n",
    "#                 for uc_name in pairing_data['upper_category_names'][pairing_data['name'] == ingredient_name].iloc[0]:\n",
    "#                     if uc_name in ingredients_list and not uc_name in already_checked:\n",
    "#                         upper_category_pairs.append([ingredient_name, uc_name])\n",
    "#                 for ud_name in pairing_data['upper_direct_names'][pairing_data['name'] == ingredient_name].iloc[0]:\n",
    "#                     if ud_name in ingredients_list and not ud_name in already_checked:\n",
    "#                         upper_direct_pairs.append([ingredient_name, ud_name])\n",
    "#                 already_checked.append(ingredient_name)\n",
    "\n",
    "#             lower_pairs = lower_category_pairs + lower_direct_pairs\n",
    "#             upper_pairs = upper_category_pairs + upper_direct_pairs\n",
    "#             all_pairs = lower_pairs + upper_pairs\n",
    "\n",
    "#     #         all_pairs_sp = [tuple(sorted(pair)) for pair in all_pairs]\n",
    "#     #         print(len(all_pairs_sp), len(list(set(all_pairs_sp))))\n",
    "\n",
    "#     #         print('INGREDIENTS', ingredients_list)\n",
    "#     #         print()\n",
    "#     #         print('LC PAIRS', lower_category_pairs)\n",
    "#     #         print()\n",
    "#     #         print()\n",
    "\n",
    "#             G = nx.Graph()\n",
    "#             G.add_nodes_from(selected_ingredients['name'].values.tolist())\n",
    "#             G.add_edges_from(all_pairs)\n",
    "#             n_subgraphs = len(list(nx.connected_component_subgraphs(G)))\n",
    "\n",
    "#         score = 0\n",
    "\n",
    "#     # SIMPLER ALTERNATIVE: bonus for proportion of actual pairs over possible pairs? could then combine with pair strength bonus?\n",
    "#     # PAIRING DENSITY BONUS ============================================================================================\n",
    "#         # ranges from roughly (.1 to 1) * 4\n",
    "#         average_shortest_path_length = nx.average_shortest_path_length(G)\n",
    "#         average_shortest_path_score = 2.5 / average_shortest_path_length - 1.1\n",
    "#     #     print(average_shortest_path_score)\n",
    "#         score += average_shortest_path_score * 4    \n",
    "\n",
    "#     # # UPPER PAIRING BONUS ==============================================================================================\n",
    "#     #     # ranges from roughly (.25 to 1) * 3\n",
    "#     #     upper_proportion_score = len(upper_pairs) / len(all_pairs) * 2.5 # messed with this, not sure if it still works\n",
    "#     # #     print(upper_proportion_score)\n",
    "#     # #     print(len(upper_pairs), len(lower_pairs), len(all_pairs))\n",
    "#     # #     print()\n",
    "#     #     score += upper_proportion_score * 3\n",
    "\n",
    "#     # PAIR STRENGTH BONUS ==============================================================================================\n",
    "#         # ranges from roughly (0 to 1) * 3\n",
    "\n",
    "#         # I'm thinking of 'lower category' as default, and awarding points for steps up from that\n",
    "#         ld_bonus = 1*len(lower_direct_pairs)\n",
    "#         uc_bonus = 2*len(upper_category_pairs)\n",
    "#         ud_bonus = 5*len(upper_direct_pairs)\n",
    "#         pair_strength_score = .6*(ld_bonus + uc_bonus + ud_bonus)/len(all_pairs) # otherwise would tend toward large stir_frys\n",
    "#     #     print('LC', len(lower_category_pairs))\n",
    "#     #     print('LD', len(lower_direct_pairs))\n",
    "#     #     print('UC', len(upper_category_pairs))\n",
    "#     #     print('UD', len(upper_direct_pairs))\n",
    "#     #     print('SCORE', pair_strength_score)\n",
    "#     #     print()\n",
    "#         score += pair_strength_score * 3\n",
    "\n",
    "#     # important but easy to avoid, so not weighted too heavily\n",
    "#     # CLASH PENALTY ====================================================================================================\n",
    "#         # ranges from roughly (0 to 1) * -1.5\n",
    "#         all_clashing_pairs = []\n",
    "#         selected_ingredients_list = selected_ingredients['name'].values.tolist()\n",
    "#         for name in selected_ingredients_list:\n",
    "#             names_that_clash_with_name = clashes_with_data['all_clashes_with_names'][clashes_with_data['name'] == name].iloc[0]\n",
    "#             all_clashing_names = set(selected_ingredients_list).intersection(set(names_that_clash_with_name)) # selected names that clash with this selected name\n",
    "#             all_clashing_pairs += [tuple(sorted([name, all_clashing_name])) for all_clashing_name in all_clashing_names]\n",
    "\n",
    "#         all_clashing_pairs = list(set(all_clashing_pairs))\n",
    "#         all_clashing_pairs_score = len(list(all_clashing_pairs)) / 4\n",
    "#         score += len(all_clashing_pairs) * -1.5\n",
    "\n",
    "#     # # FRUIT BONUS ======================================================================================================\n",
    "#     #     # ranges from roughly (0 to 3) * .1\n",
    "#     #     n_fruit = len(selected_ingredients[selected_ingredients['fruit'] == 'y'])\n",
    "#     #     score += n_fruit * .1\n",
    "\n",
    "#     # # NUT SEED BONUS ===================================================================================================    \n",
    "#     #     # ranges from roughly (0 to 2) * .15\n",
    "#     #     n_nut_seed = len(selected_ingredients[selected_ingredients['protein_nut_seed'] == 'y'])\n",
    "#     #     score += n_nut_seed * .15\n",
    "\n",
    "#     # FLAVOR BALANCE BONUS =============================================================================================\n",
    "#         # ranges from roughly (0 to 1) * 1\n",
    "#         n_sweet_lower = len(selected_ingredients[selected_ingredients['sweet'] == 'y'])\n",
    "#         n_sweet_upper = len(selected_ingredients[selected_ingredients['sweet'] == 'Y'])\n",
    "#         n_salty_lower = len(selected_ingredients[selected_ingredients['salty'] == 'y'])\n",
    "#         n_salty_upper = len(selected_ingredients[selected_ingredients['salty'] == 'Y'])\n",
    "#         n_sour_lower = len(selected_ingredients[selected_ingredients['sour'] == 'y'])\n",
    "#         n_sour_upper = len(selected_ingredients[selected_ingredients['sour'] == 'Y'])\n",
    "#         n_savory_lower = len(selected_ingredients[selected_ingredients['savory'] == 'y'])\n",
    "#         n_savory_upper = len(selected_ingredients[selected_ingredients['savory'] == 'Y'])\n",
    "#         n_bitter_lower = len(selected_ingredients[selected_ingredients['bitter'] == 'y'])\n",
    "#         n_bitter_upper = len(selected_ingredients[selected_ingredients['bitter'] == 'Y'])\n",
    "#         n_spicy_lower = len(selected_ingredients[selected_ingredients['spicy'] == 'y'])\n",
    "#         n_spicy_upper = len(selected_ingredients[selected_ingredients['spicy'] == 'Y'])\n",
    "\n",
    "#         # each varies from roughly .5 to 1\n",
    "#         sweet_score = (n_sweet_lower/2 + n_sweet_upper)/5\n",
    "#         salty_score = (n_salty_lower/2 + n_salty_upper)*2/5\n",
    "#         sour_score = (n_sour_lower/2 + n_sour_upper)*2/5\n",
    "#         savory_score = (n_savory_lower/2 + n_savory_upper)*3/5\n",
    "#         bitter_score = (n_bitter_lower/2 + n_bitter_upper)*3/5\n",
    "#         spicy_score = (n_spicy_lower/2 + n_spicy_upper)*2/5\n",
    "\n",
    "#         flavor_balance_score = 5 / (1 + abs(1-sweet_score) + abs(1-salty_score) + abs(1-sour_score) + abs(1-savory_score) + abs(1-spicy_score)) - 1.25\n",
    "#     #     print(flavor_balance_score)\n",
    "\n",
    "#         score += flavor_balance_score\n",
    "#     #     print(sweet_score, salty_score, sour_score, savory_score, bitter_score, spicy_score)\n",
    "#     #     print()\n",
    "\n",
    "#     #     print(n_sweet_lower, n_sweet_upper)\n",
    "#     #     print(n_salty_lower, n_salty_upper)\n",
    "#     #     print(n_sour_lower, n_sour_upper)\n",
    "#     #     print(n_savory_lower, n_savory_upper)\n",
    "#     #     print(n_bitter_lower, n_bitter_upper)\n",
    "#     #     print(n_spicy_lower, n_spicy_upper)\n",
    "#     #     print()\n",
    "\n",
    "#     # TEXTURE BALANCE BONUS ============================================================================================\n",
    "#         # ranges from roughly (0 to 1) * .75\n",
    "#         n_crunchy_lower = len(selected_ingredients[selected_ingredients['stir_fry_crunchy'] == 'y'])\n",
    "#         n_crunchy_upper = len(selected_ingredients[selected_ingredients['stir_fry_crunchy'] == 'Y'])\n",
    "#         n_chewy_lower = len(selected_ingredients[selected_ingredients['stir_fry_chewy'] == 'y'])\n",
    "#         n_chewy_upper = len(selected_ingredients[selected_ingredients['stir_fry_chewy'] == 'Y'])\n",
    "#         n_juicy_lower = len(selected_ingredients[selected_ingredients['stir_fry_juicy'] == 'y'])\n",
    "#         n_juicy_upper = len(selected_ingredients[selected_ingredients['stir_fry_juicy'] == 'Y'])\n",
    "\n",
    "#         # each ranges from roughly 0 to 1\n",
    "#         crunchy_score = (n_crunchy_lower/2 + n_crunchy_upper)/3\n",
    "#         chewy_score = (n_chewy_lower/2 + n_chewy_upper)\n",
    "#         juicy_score = (n_juicy_lower/2 + n_juicy_upper)/3\n",
    "#     #     print(crunchy_score, chewy_score, juicy_score)\n",
    "\n",
    "#         texture_balance_score = 4 / (1 + abs(1-crunchy_score) + abs(1-chewy_score) + abs(1-juicy_score)) - 1\n",
    "#     #     print(texture_balance_score)\n",
    "#     #     print()\n",
    "\n",
    "#         score += texture_balance_score * .75\n",
    "\n",
    "#     # seems like it's hard to balance food groups on top of everything else. pity the scores aren't more independent\n",
    "#     # FOOD GROUP BALANCE BONUS =========================================================================================\n",
    "#         # ranges from roughly (25 to 1) * 2\n",
    "#         n_fruit = len(selected_ingredients[selected_ingredients['fruit'] == 'y'])\n",
    "#         n_veg = len(selected_ingredients[selected_ingredients['veg'] == 'y'])\n",
    "#         n_protein = len(selected_ingredients[selected_ingredients['protein'] == 'y'])\n",
    "\n",
    "#         # each varies from roughly 0 to 1 (sometimes a little over)\n",
    "#         fruit_score = n_fruit / 3\n",
    "#         veg_score = n_veg / 5\n",
    "#         protein_score = n_protein / 3\n",
    "#     #     print(fruit_score, veg_score, protein_score)\n",
    "\n",
    "#         food_group_balance_score = 3 / (1 + abs(1-fruit_score) + abs(1-veg_score) + abs(1-protein_score)) - .75\n",
    "#     #     print(food_group_balance_score)\n",
    "#     #     print()\n",
    "\n",
    "#         score += food_group_balance_score * 2\n",
    "\n",
    "#         if score > top_score:\n",
    "#             top_score = score\n",
    "#             top_food_group_balance_score = food_group_balance_score\n",
    "#             top_average_shortest_path_score = average_shortest_path_score\n",
    "#             top_flavor_balance_score = flavor_balance_score\n",
    "#             top_texture_balance_score = texture_balance_score\n",
    "#             top_all_clashing_pairs_score = all_clashing_pairs_score\n",
    "#             top_pair_strength_score = pair_strength_score\n",
    "#     #         top_upper_pairs = upper_pairs\n",
    "#     #         top_lower_pairs = lower_pairs\n",
    "#             top_lc_pairs = lower_category_pairs\n",
    "#             top_ld_pairs = lower_direct_pairs\n",
    "#             top_uc_pairs = upper_category_pairs\n",
    "#             top_ud_pairs = upper_direct_pairs\n",
    "#             top_selected_ingredients = selected_ingredients\n",
    "#             top_average_shortest_path_length = average_shortest_path_length\n",
    "#             top_all_clashing_pairs = all_clashing_pairs\n",
    "#     #         top_upper_proportion = len(upper_pairs) / (len(upper_pairs) + len(lower_pairs))\n",
    "#     # print('TOP AVG SHORTEST PATH LENGTH', top_average_shortest_path_length)\n",
    "#     # print('TOP UPPER PROPORTION', top_upper_proportion)\n",
    "# #     print('TOP AVERAGE SHORTEST PATH SCORE', top_average_shortest_path_score * 4)\n",
    "# #     print('TOP PAIR STRENGTH SCORE', top_pair_strength_score * 3)\n",
    "# #     print('TOP ALL CLASHING PAIRS SCORE', top_all_clashing_pairs_score * -1.5)\n",
    "# #     print('TOP FLAVOR BALANCE SCORE', top_flavor_balance_score)\n",
    "# #     print('TOP TEXTURE BALANCE SCORE', top_texture_balance_score * .75)\n",
    "# #     print('TOP FOOD GROUP BALANCE SCORE', top_food_group_balance_score * 2)\n",
    "# #     print('TOP_SCORE', top_score)  \n",
    "    \n",
    "#     vegan = top_selected_ingredients['not_vegan'].sum() == ''\n",
    "#     gluten_free = top_selected_ingredients['gluten'].sum() == ''\n",
    "    \n",
    "#     recipe_greens = top_selected_ingredients[top_selected_ingredients['stir_fry_green'] == 'y']\n",
    "#     recipe_extras = top_selected_ingredients[top_selected_ingredients['stir_fry_extra'] == 'y']\n",
    "#     recipe_dressing_oils = top_selected_ingredients[top_selected_ingredients['stir_fry_dressing_oil'] == 'y']\n",
    "#     recipe_dressing_vinegars = top_selected_ingredients[top_selected_ingredients['stir_fry_dressing_vinegar'] == 'y']\n",
    "#     recipe_dressing_salts = top_selected_ingredients[top_selected_ingredients['stir_fry_dressing_salt'] == 'y']\n",
    "#     recipe_dressing_peppers = top_selected_ingredients[top_selected_ingredients['stir_fry_dressing_pepper'] == 'y']\n",
    "#     recipe_dressing_garlics = top_selected_ingredients[top_selected_ingredients['stir_fry_dressing_garlic'] == 'y']\n",
    "#     # could just select 'stir_fry_dressing', but this includes garlics\n",
    "#     recipe_dressing = recipe_dressing_oils.append(recipe_dressing_vinegars).append(recipe_dressing_salts).append(recipe_dressing_peppers)\n",
    "\n",
    "#     new_recipe = pd.DataFrame({\n",
    "#         'vegan': [vegan],\n",
    "#         'gluten_free': [gluten_free],\n",
    "#         'basic': [stir_fry_data_is_basic],\n",
    "#         'best_of': [best_of],\n",
    "#         'score': [top_score],\n",
    "#         'pairing_density_bonus': [top_average_shortest_path_score * 4],\n",
    "#         'pair_strength_bonus': [top_pair_strength_score * 3],\n",
    "#         'clash_penalty': [top_all_clashing_pairs_score * 4],\n",
    "#         'flavor_balance_bonus': [top_flavor_balance_score],\n",
    "#         'texture_balance_bonus': [top_texture_balance_score * 75],\n",
    "#         'food_group_balance_bonus': [top_food_group_balance_score * 2],\n",
    "#         'lc_pairs': [top_lc_pairs],\n",
    "#         'ld_pairs': [top_ld_pairs],\n",
    "#         'uc_pairs': [top_uc_pairs],\n",
    "#         'ud_pairs':[top_ud_pairs],\n",
    "#         'clashing_pairs': [top_all_clashing_pairs],\n",
    "#         'ingredient_names': [top_selected_ingredients['name'].values.tolist()],\n",
    "#         'leafy_green_names': [recipe_greens['name'].values.tolist()],\n",
    "#         'extra_names': [recipe_extras['name'].values.tolist()],\n",
    "#         'dressing_names': [recipe_dressing['name'].values.tolist()],\n",
    "#     })\n",
    "#     stir_fry_recipe_data = stir_fry_recipe_data.append(new_recipe, sort=False)\n",
    "#     print('stir_fry RECIPE RECORDED. SCORE:', top_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import date\n",
    "# today = date.today()\n",
    "# date_string = f'{str(today.year)}_{str(today.month)}_{str(today.day)}'\n",
    "\n",
    "# stir_fry_recipe_data.to_pickle(os.path.join(root_path, 'DATA/stir_fry_recipe_data_latest.pickle'))\n",
    "# stir_fry_recipe_data.to_pickle(os.path.join(root_path, f'DATA/stir_fry_recipe_data_{date_string}.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Displaying flavor tool generator records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install pyvis\n",
    "\n",
    "# from pyvis import network as net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe = stir_fry_recipe_data[(stir_fry_recipe_data['basic'] == True) & (stir_fry_recipe_data['vegan'] == True) & stir_fry_recipe_data['gluten_free'] == True].sample(1).iloc[0]\n",
    "# recipe_net = net.Network(notebook=True)\n",
    "\n",
    "# nodes = recipe['ingredient_names']\n",
    "\n",
    "# nodes_color = []\n",
    "# for name in recipe['ingredient_names']:\n",
    "#     ingredient = stir_fry_data[stir_fry_data['name'] == name].iloc[0]\n",
    "#     if ingredient['stir_fry_green'] == 'y':\n",
    "#         nodes_color.append('lightgreen')\n",
    "#     elif ingredient['stir_fry_extra'] == 'y':\n",
    "#         if ingredient['veg'] == 'y':\n",
    "#             nodes_color.append('green')\n",
    "#         elif ingredient['fruit'] == 'y':\n",
    "#             nodes_color.append('orange')\n",
    "#         elif ingredient['protein_nut_seed'] == 'y':\n",
    "#             nodes_color.append('brown')\n",
    "#         else:\n",
    "#             nodes_color.append('lightblue')\n",
    "#     elif ingredient['stir_fry_dressing'] == 'y':\n",
    "#         nodes_color.append('lightgrey')  \n",
    "        \n",
    "# recipe_net.add_nodes(\n",
    "#     nodes=nodes,\n",
    "#     color=nodes_color\n",
    "# )\n",
    "\n",
    "# for pair in recipe['lc_pairs']:\n",
    "#     recipe_net.add_edge(pair[0], pair[1], physics=False, color='lightgrey')\n",
    "\n",
    "# for pair in recipe['ld_pairs']:\n",
    "#     recipe_net.add_edge(pair[0], pair[1], physics=False, color='grey')\n",
    "    \n",
    "# for pair in recipe['uc_pairs']:\n",
    "#     recipe_net.add_edge(pair[0], pair[1], color='darkgrey')\n",
    "    \n",
    "# for pair in recipe['ud_pairs']:\n",
    "#     recipe_net.add_edge(pair[0], pair[1], color='black')\n",
    "\n",
    "# if not recipe['vegan']:\n",
    "#     print('NOT VEGAN')\n",
    "# if not recipe['gluten_free']:\n",
    "#     print('CONTAINS GLUTEN')\n",
    "# print('SCORE:', recipe['score'])\n",
    "# recipe_net.show('recipe_net.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
