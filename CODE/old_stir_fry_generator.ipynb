{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "import math\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.dirname(os.getcwd())\n",
    "ingredients_data_raw = pd.read_csv(os.path.join(root_path, 'DATA/ingredients_data.csv'))\n",
    "ingredients_data = ingredients_data_raw.replace(float('nan'), '')\n",
    "stir_fry_data_impractical = ingredients_data[ingredients_data['stir_fry'] =='y']\n",
    "stir_fry_data = ingredients_data[(ingredients_data['stir_fry_yes'] == 'y') & (ingredients_data['salad_umbrella'] != 'y') & (ingredients_data['redirect'] != 'y')]\n",
    "\n",
    "stir_fry_data_basic = stir_fry_data[stir_fry_data['stir_fry_basic'] == 'y']\n",
    "# stir_fry_data = stir_fry_data_basic\n",
    "stir_fry_data_is_basic = False\n",
    "\n",
    "stir_fry_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Matching \"pairs with\" terms to ingredient names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terms_from_pairs_with(pairs_with):\n",
    "    if str(pairs_with) == 'nan':\n",
    "        return []\n",
    "    else:\n",
    "        return [term.strip() for term in pairs_with.split('\\n\\n') if term.strip() != '']\n",
    "\n",
    "# break entries in column that has 'pairs with' strings into lists of ingredient terms\n",
    "ingredient_pairs_with_terms = stir_fry_data['pairs_with'].apply(get_terms_from_pairs_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of all terms, ignoring case and excluding duplicates\n",
    "all_terms = list(set(ingredient_pairs_with_terms.sum()))\n",
    "all_terms_lower = list(set([term.lower() for term in ingredient_pairs_with_terms.sum()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install inflect\n",
    "import inflect\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "    # replace numbers w c, C\n",
    "    # auto caps\n",
    "    # import salad, overwrite\n",
    "    # guess at direct match\n",
    "    \n",
    "# how to tell if direct match:\n",
    "    # if term has e.g.\n",
    "        # if first name token is followed by comma then another term\n",
    "            # first tokens match and term contains second name token OR term contains token, comma, token\n",
    "        # else:\n",
    "            # return: term contains first name token\n",
    "    # else:\n",
    "        # if first name token is followed by comma then another term\n",
    "            # return: term contains reversed name tokens OR term contains token, comma, token\n",
    "        # else:\n",
    "            # return: term contains first name token\n",
    "            \n",
    "# how to tell if category match:\n",
    "    # if term has e.g.\n",
    "        # if first name token is followed by comma then another term\n",
    "            # if first tokens match\n",
    "                # if term contains second name token\n",
    "                    # return d\n",
    "                # else:\n",
    "                    # return c\n",
    "            # else:\n",
    "                # return ''\n",
    "        # else:\n",
    "            # if first tokens match (before e.g. in term):\n",
    "                # return c\n",
    "            # elif name token in matches after e.g.\n",
    "                # return d\n",
    "            # else:\n",
    "                # return ''\n",
    "            # return: term contains first name token\n",
    "    # else:\n",
    "        # if first name token is followed by comma then another term\n",
    "            # if term contains reversed name tokens OR term contains token, comma, token\n",
    "                # return d\n",
    "            # elif term contains first name token:\n",
    "                # return c\n",
    "            # else:\n",
    "                # return ''\n",
    "        # else:\n",
    "            # if first name token in term:\n",
    "                # return direct\n",
    "            # elif any common tokens:\n",
    "                # return c\n",
    "            # else:\n",
    "                # return ''\n",
    "\n",
    "salad_matches = pd.read_csv(os.path.join(root_path, 'DATA/term_name_matches_specific.csv'))\n",
    "    \n",
    "def get_tokens(phrase):\n",
    "    tokens = [token.strip() for token in re.split('\\(|\\)|,|e\\.g\\.|esp\\.|and|—|or|aka|see|see also|;|and\\/or|\\*', phrase)]\n",
    "#     print(tokens)\n",
    "    tokens = [p.singular_noun(token) or token for token in tokens if token != '']\n",
    "#     print(tokens)\n",
    "    return tokens\n",
    "\n",
    "def get_mark(name, term):\n",
    "#     print()\n",
    "#     print('NAME', name)\n",
    "#     print('TERM', term)\n",
    "    try:\n",
    "        salad_match = salad_matches[term][salad_matches['name'] == name].iloc[0]\n",
    "#         print('SALAD MATCH', salad_match)\n",
    "    except:\n",
    "#         print('NO SALAD MATCH')\n",
    "        salad_match = None \n",
    "    if salad_match:\n",
    "        if str(salad_match) in ['0', 'nan']:\n",
    "#             print('BAD SALAD MATCH')\n",
    "            return ''\n",
    "        else:\n",
    "#             print('GOOD SALAD MATCH', salad_match)\n",
    "#             print('NAME', name)\n",
    "#             print('TERM', term)\n",
    "#             print()\n",
    "            return salad_match\n",
    "    \n",
    "    name_tokens = [token.lower() for token in get_tokens(name)]  \n",
    "    term_tokens_mixed = get_tokens(term)\n",
    "    term_tokens = [token.lower() for token in term_tokens_mixed]\n",
    "    \n",
    "    primary_name = re.split('\\(|—|e\\.g\\.', name)[0].strip()\n",
    "    primary_name_split = primary_name.split(', ')\n",
    "    single_comma_primary_name = len(primary_name_split) == 2\n",
    "    \n",
    "#     print()\n",
    "    if 'e.g.' in term:\n",
    "        if single_comma_primary_name:\n",
    "            if name_tokens[0] == term_tokens[0]:\n",
    "                if name_tokens[1] in term_tokens: # specific name in e.g. term\n",
    "#                     print('NAME TOKENS In TERM TOKENS')\n",
    "                    term_i = term_tokens.index(name_tokens[1])\n",
    "                    if term_tokens_mixed[term_i] == term_tokens_mixed[term_i].upper():\n",
    "                        match = 'D'\n",
    "                    else:\n",
    "                        if term_tokens_mixed[0] == term_tokens_mixed[0].upper():\n",
    "                            match = 'D'\n",
    "                        else:\n",
    "                            match = 'd'\n",
    "                else: # name matches only generic (pre e.g.) part of term\n",
    "                    if term_tokens_mixed[0] == term_tokens_mixed[0].upper():\n",
    "                        match = 'C'\n",
    "                    else:\n",
    "                        match = 'c'\n",
    "            else:\n",
    "                match = ''\n",
    "        else:\n",
    "            if name_tokens[0] == term_tokens[0]: # name matches term before e.g.\n",
    "                if term_tokens_mixed[0] == term_tokens_mixed[0].upper():\n",
    "                    match = 'C'\n",
    "                else:\n",
    "                    match = 'c'\n",
    "            elif name_tokens[0] in term_tokens[1:]: # name matches term after e.g.\n",
    "                term_i = term_tokens.index(name_tokens[0])\n",
    "                if term_tokens_mixed[term_i] == term_tokens_mixed[term_i].upper():\n",
    "                    match = 'D'\n",
    "                else:\n",
    "                    if term_tokens_mixed[0] == term_tokens_mixed[0].upper():\n",
    "                        match = 'D'\n",
    "                    else:\n",
    "                        match = 'd'\n",
    "            else:\n",
    "                match = ''\n",
    "    else:\n",
    "        if single_comma_primary_name:\n",
    "            if ' '.join(primary_name_split).lower() in term.lower() or primary_name.lower() in term.lower(): # if primary_name is in term, any order\n",
    "                if term_tokens_mixed[0] == term_tokens_mixed[0].upper():\n",
    "                    match = 'D'\n",
    "                else:\n",
    "                    match = 'd'\n",
    "            elif name_tokens[0] == term_tokens[0]: # if first part of primary name matches first token in term\n",
    "                if term_tokens_mixed[0] == term_tokens_mixed[0].upper():\n",
    "                    match = 'C'\n",
    "                else:\n",
    "                    match = 'c'\n",
    "            else:\n",
    "                match = ''\n",
    "        else:\n",
    "            if name_tokens[0] in term_tokens: # if non-comma name anywhere in non-e.g. term_tokens\n",
    "                if term_tokens_mixed[0] == term_tokens_mixed[0].upper():\n",
    "                    match = 'D'\n",
    "                else:\n",
    "                    match = 'd'\n",
    "            elif len(set(name_tokens).intersection(set(term_tokens))) > 0: # if there are any common tokens\n",
    "                if term_tokens_mixed[0] == term_tokens_mixed[0].upper():\n",
    "                    match = 'C'\n",
    "                else:\n",
    "                    match = 'c'\n",
    "            else:\n",
    "                match = ''\n",
    "                \n",
    "    if match == '':\n",
    "        n_common = len(set(name_tokens).intersection(set(term_tokens)))\n",
    "        if n_common != 0:\n",
    "            match = n_common\n",
    "        \n",
    "#     print('MATCH', match)\n",
    "#     if match != '':\n",
    "#         print('MATCH', match)\n",
    "#         print('TERM', term)\n",
    "#         print('NAME', name)\n",
    "#         print()\n",
    "    return match\n",
    "\n",
    "# failings\n",
    "    # straight matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALMONDS (and UNSWEETENED ALMOND BUTTER; see also MILK, ALMOND)\n",
      "ANISE SEEDS\n",
      "APPLES (and APPLE CIDER, APPLE JUICE and/or APPLESAUCE)\n",
      "ARUGULA (aka ROCKET)\n",
      "ASPARAGUS\n",
      "BASIL\n",
      "BEANS, BLACK (aka TURTLE BEANS)\n",
      "BEANS, PINTO\n",
      "BEETS\n",
      "BELL PEPPERS—IN GENERAL, or MIXED\n",
      "BOK CHOY (aka CHINESE CABBAGE or PAK CHOI)\n",
      "BRAGG LIQUID AMINOS\n",
      "BROCCOLI\n",
      "BROCCOLINI\n",
      "BRUSSELS SPROUTS\n",
      "BUTTER\n",
      "CABBAGE, GREEN\n",
      "CABBAGE, RED\n",
      "CARROTS\n",
      "CASHEWS and CASHEW NUT BUTTER\n",
      "CAULIFLOWER\n",
      "CELERY\n",
      "CHARD, e.g., RAINBOW, RED/RUBY, SWISS, or MIXED\n",
      "CHEESE, CHEDDAR\n",
      "CHEESE, PARMESAN\n",
      "CHICKPEAS (aka GARBANZO BEANS)\n",
      "CHILES, HABANERO\n",
      "CHILES, JALAPEÑO\n",
      "CHILI PEPPER FLAKES\n",
      "CHILI POWDER\n",
      "CHIVES\n",
      "CILANTRO (aka CHINESE PARSLEY or FRESH CORIANDER LEAF)\n",
      "COCONUT BUTTER\n",
      "CORN\n",
      "CORNMEAL and POLENTA (see also GRITS)\n",
      "CUMIN\n",
      "EGGPLANT (aka AUBERGINE)\n",
      "FENNEL\n",
      "FENNEL SEEDS\n",
      "FLAXSEEDS\n",
      "GARLIC\n",
      "GINGER—IN GENERAL\n",
      "GREENS, BEET\n",
      "GREENS, DANDELION\n",
      "HONEY—IN GENERAL\n",
      "KALE\n",
      "LEEKS\n",
      "LEGUMES (see also specific BEANS, CHICKPEAS, LENTILS, PEANUTS, PEAS, and SOYBEANS)\n",
      "LEMONS\n",
      "LENTILS, BROWN\n",
      "LENTILS, GREEN\n",
      "LENTILS, YELLOW\n",
      "LIMES (e.g., JUICE, ZEST)\n",
      "LIQUID SMOKE\n",
      "MANGOES\n",
      "MILK, ALMOND\n",
      "MILK, e.g., WHOLE or NONFAT—IN GENERAL\n",
      "MILK, SOY\n",
      "MILLET\n",
      "MUSHROOMS, BUTTON (aka WHITE MUSHROOMS)\n",
      "MUSHROOMS, CHANTERELLE\n",
      "MUSHROOMS, CREMINI (aka CRIMINI or ITALIAN BROWN MUSHROOMS)\n",
      "MUSHROOMS, OYSTER\n",
      "MUSHROOMS, PORCINI (aka BOLETES or CÈPES; see also MUSHROOMS, WILD)\n",
      "MUSHROOMS, PORTOBELLO\n",
      "MUSHROOMS, SHIITAKE—DRIED and FRESH\n",
      "MUSTARD POWDER (aka DRY MUSTARD)\n",
      "MUSTARD, e.g., DIJON (see also GREENS, MUSTARD; MUSTARD POWDER; MUSTARD SEEDS)\n",
      "NUTRITIONAL YEAST (aka affectionately as NOOCH)\n",
      "OIL, CANOLA\n",
      "OIL, COCONUT\n",
      "OIL, OLIVE\n",
      "OIL, PEANUT\n",
      "OIL, SESAME\n",
      "OIL, VEGETABLE\n",
      "OLIVES, KALAMATA\n",
      "OLIVES, PICHOLINE\n",
      "ONIONS, PEARL\n",
      "ONIONS, RED (see also ONIONS)\n",
      "ONIONS, SPRING (see also SCALLIONS)\n",
      "ONIONS, VIDALIA\n",
      "ORANGES, ORANGE JUICE, and ORANGE ZEST\n",
      "OREGANO\n",
      "PAPAYA (i.e., RED)\n",
      "PAPRIKA (see also PAPRIKA, SMOKED)\n",
      "PAPRIKA, SMOKED (aka PIMENTON or PIMENTON DE LA VERA)\n",
      "PARSLEY, generally ITALIAN (aka FLAT-LEAF PARSLEY)\n",
      "PARSNIPS\n",
      "PEANUTS and PEANUT BUTTER\n",
      "PEARS—IN GENERAL\n",
      "PEAS, SPLIT\n",
      "PEPPER, BLACK\n",
      "PEPPER, WHITE\n",
      "PEPPERMINT\n",
      "PINE NUTS (aka PIGNOLI)\n",
      "PINEAPPLE\n",
      "PISTACHIOS\n",
      "PLANTAINS—IN GENERAL, or MIXED\n",
      "PLANTAINS, GREEN\n",
      "PLANTAINS, SWEET (e.g., BROWN or YELLOW)\n",
      "POMEGRANATES and POMEGRANATE JUICE (see also POMEGRANATE MOLASSES)\n",
      "POTATOES, BLUE (or PURPLE)\n",
      "POTATOES, FINGERLING\n",
      "POTATOES, NEW (aka RED POTATOES)\n",
      "POTATOES, RUSSET\n",
      "POTATOES, THICK-SKINNED (e.g., IDAHO, RUSSET)\n",
      "POTATOES, THIN-SKINNED (e.g., NEW POTATOES, WHITE POTATOES)\n",
      "POTATOES, YELLOW (e.g., YUKON GOLD)\n",
      "PUMPKIN (see also SQUASH, WINTER)\n",
      "QUINOA\n",
      "RADISHES—IN GENERAL (see also DAIKON)\n",
      "RAISINS\n",
      "RICE, BASMATI, and BROWN BASMATI RICE\n",
      "RICE, BLACK (aka FORBIDDEN RICE)\n",
      "RICE, JASMINE (see also THAI CUISINE)\n",
      "RICE, WILD\n",
      "ROSEMARY\n",
      "SAFFRON\n",
      "SAGE\n",
      "SALT, BLACK\n",
      "SALT, HIMALAYAN\n",
      "SALT, KOSHER\n",
      "SALT, SEA\n",
      "SALT, SMOKED\n",
      "SAUERKRAUT\n",
      "SCALLIONS (aka GREEN ONIONS or SPRING ONIONS)\n",
      "SEEDS, PUMPKIN\n",
      "SEEDS, SUNFLOWER\n",
      "SEITAN (see also tips for NAMA-FU)\n",
      "SESAME SEEDS—IN GENERAL (aka GOMA)\n",
      "SHALLOTS\n",
      "SNOW PEAS (aka CHINESE PEA PODS) (see also SUGAR SNAP PEAS)\n",
      "SORREL\n",
      "SPINACH\n",
      "SQUASH, ACORN (see also SQUASH, WINTER)\n",
      "SQUASH, BUTTERNUT (see also SQUASH, WINTER)\n",
      "SQUASH, SUMMER (see also CHAYOTE; SQUASH, CROOKNECK; SQUASH, PATTY PAN; and ZUCCHINI)\n",
      "SRIRACHA (aka CHILI GARLIC SAUCE)\n",
      "STOCK, MUSHROOM\n",
      "STOCK, VEGETABLE (see also DASHI)\n",
      "SUGAR SNAP PEAS (aka SNAP PEAS)\n",
      "SWEET POTATOES\n",
      "TAMARI\n",
      "TEMPEH\n",
      "THYME\n",
      "TOFU, FIRM or EXTRA-FIRM\n",
      "TOFU, SCRAMBLED\n",
      "TOFU, SILKEN\n",
      "TOFU, SMOKED\n",
      "TOFU, SOFT\n",
      "TOFU, SUPER-FIRM\n",
      "TOMATILLOS\n",
      "TOMATOES, GREEN\n",
      "TOMATOES, SUN-DRIED (or OVEN-DRIED TOMATOES)\n",
      "TOMATOES, TOMATO JUICE, TOMATO PASTE, and TOMATO SAUCE\n",
      "TRUFFLES, BLACK\n",
      "TRUFFLES, WHITE\n",
      "TURMERIC (see also CURRY POWDER, which contains turmeric)\n",
      "TURNIPS (see also GREENS, TURNIP)\n",
      "VINEGAR, APPLE CIDER (aka VINEGAR, CIDER)\n",
      "VINEGAR, BALSAMIC\n",
      "VINEGAR, RED WINE (see also VINEGAR, WINE–IN GENERAL)\n",
      "WALNUTS\n",
      "YAMS\n",
      "ZUCCHINI (see also SQUASH, SUMMER)\n",
      "LEMONGRASS\n",
      "MISO, DARK\n",
      "ARTICHOKE HEARTS (see also ARTICHOKES)\n",
      "ARTICHOKES, JERUSALEM (aka SUNCHOKES)\n",
      "BAY LEAF\n",
      "CARAWAY SEEDS\n",
      "CELERY ROOT (aka CELERIAC)\n",
      "CHESTNUTS\n",
      "CHIA SEEDS\n",
      "CHILES, CHIPOTLE\n",
      "CHILES, SERRANO\n",
      "CHIVES, GARLIC (aka CHINESE CHIVES)\n",
      "COCONUT WATER\n",
      "DILL SEEDS (see also DILL and DILL WEED)\n",
      "DILL WEED (see also DILL and DILL SEEDS)\n",
      "ENDIVE (aka BELGIAN ENDIVE)\n",
      "FENNEL FRONDS (or LEAVES)\n",
      "FENUGREEK\n",
      "FIDDLEHEAD FERNS\n",
      "FLOWERS, EDIBLE\n",
      "GARLIC, GREEN (aka BABY GARLIC or SPRING GARLIC)\n",
      "GINGER, POWDERED (i.e., dried, ground)\n",
      "GREENS, COLLARD\n",
      "HAZELNUTS (aka FILBERTS)\n",
      "KELP, KELP GRANULES, and KELP POWDER (see also ARAME, KOMBU, SEA VEGETABLES, and WAKAME)\n",
      "LAVENDER\n",
      "LEMON VERBENA\n",
      "MILK, COCONUT\n",
      "MILK, GOAT\n",
      "MILK, HEMP\n",
      "MUSHROOMS, BLACK TRUMPET\n",
      "MUSHROOMS, CHICKEN OF THE WOODS\n",
      "MUSHROOMS, MOREL\n",
      "MUSTARD SEEDS\n",
      "NETTLES (aka STINGING NETTLES)\n",
      "NOODLES, RICE (aka RICE STICKS—or RICE VERMICELLI, which are thinner strands)\n",
      "NUTS, BRAZIL\n",
      "NUTS, MACADAMIA\n",
      "OIL, FLAXSEED\n",
      "EGGS (e.g., FRESH)\n",
      "FRUITS AND VEGETABLES, FROZEN\n"
     ]
    }
   ],
   "source": [
    "# doing it this way so I can add 'print' to monitor progress\n",
    "mark_data = []\n",
    "for name in stir_fry_data['name']:\n",
    "    print(name)\n",
    "    mark_data.append([get_mark(name, term) for term in all_terms])\n",
    "\n",
    "# term_name_marks = pd.DataFrame(mark_data, columns = all_terms)\n",
    "# term_name_marks['name'] = pd.Series(stir_fry_data['name'].values.tolist())\n",
    "\n",
    "# term_name_scores.to_csv(os.path.join(root_path, 'DATA/term_name_scores_common.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing it this way so I can add 'print' to monitor progress\n",
    "# mark_data = []\n",
    "# for name in salad_matches['name']:\n",
    "#     print(name)\n",
    "#     mark_data.append([get_mark(name, term) for term in all_terms])\n",
    "\n",
    "term_name_marks = pd.DataFrame(mark_data, columns = all_terms)\n",
    "term_name_marks['name'] = pd.Series(stir_fry_data['name'].values.tolist())\n",
    "\n",
    "# term_name_scores.to_csv(os.path.join(root_path, 'DATA/term_name_scores_common.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing it this way so I can add 'print' to monitor progress\n",
    "# mark_data = []\n",
    "# for name in salad_matches['name']:\n",
    "#     print(name)\n",
    "#     mark_data.append([get_mark(name, term) for term in all_terms])\n",
    "\n",
    "# term_name_marks = pd.DataFrame(mark_data, columns = all_terms)\n",
    "# term_name_marks['name'] = pd.Series(stir_fry_data['name'].values.tolist())\n",
    "\n",
    "term_name_marks.to_csv(os.path.join(root_path, 'DATA/stir_fry_term_name_marks.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "ALMONDS (and UNSWEETENED ALMOND BUTTER; see also MILK, ALMOND)\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "ANISE SEEDS\n",
      "1.0\n",
      "y\n",
      "Y\n",
      "Y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "c\n",
      "1.0\n",
      "y\n",
      "c\n",
      "y\n",
      "Y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "c\n",
      "y\n",
      "y\n",
      "Y\n",
      "c\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "1.0\n",
      "1.0\n",
      "c\n",
      "y\n",
      "y\n",
      "APPLES (and APPLE CIDER, APPLE JUICE and/or APPLESAUCE)\n",
      "d\n",
      "y\n",
      "Y\n",
      "y\n",
      "1.0\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "d\n",
      "y\n",
      "d\n",
      "y\n",
      "d\n",
      "y\n",
      "y\n",
      "y\n",
      "c\n",
      "d\n",
      "ARTICHOKE HEARTS (see also ARTICHOKES)\n",
      "y\n",
      "Y\n",
      "y\n",
      "1.0\n",
      "y\n",
      "y\n",
      "1\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "1\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "c\n",
      "ARTICHOKES, JERUSALEM (aka SUNCHOKES)\n",
      "d\n",
      "1.0\n",
      "y\n",
      "y\n",
      "1.0\n",
      "1\n",
      "y\n",
      "y\n",
      "1\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "Y\n",
      "c\n",
      "1\n",
      "y\n",
      "d\n",
      "y\n",
      "d\n",
      "y\n",
      "1\n",
      "d\n",
      "y\n",
      "1\n",
      "1.0\n",
      "d\n",
      "y\n",
      "y\n",
      "c\n",
      "d\n",
      "Y\n",
      "d\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "c\n",
      "ARUGULA (aka ROCKET)\n",
      "y\n",
      "y\n",
      "1\n",
      "1\n",
      "c\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "c\n",
      "1\n",
      "y\n",
      "1.0\n",
      "1\n",
      "c\n",
      "y\n",
      "1\n",
      "1\n",
      "y\n",
      "d\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "ASPARAGUS\n",
      "Y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "d\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "BASIL\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "Y\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "y\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "y\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "BAY LEAF\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "d\n",
      "y\n",
      "y\n",
      "BEANS, BLACK (aka TURTLE BEANS)\n",
      "1\n",
      "d\n",
      "y\n",
      "y\n",
      "y\n",
      "d\n",
      "1\n",
      "y\n",
      "y\n",
      "1.0\n",
      "1.0\n",
      "y\n",
      "y\n",
      "1\n",
      "y\n",
      "Y\n",
      "1.0\n",
      "y\n",
      "y\n",
      "y\n",
      "d\n",
      "BEANS, PINTO\n",
      "y\n",
      "c\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "c\n",
      "y\n",
      "y\n",
      "c\n",
      "y\n",
      "1\n",
      "y\n",
      "d\n",
      "c\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "c\n",
      "y\n",
      "Y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "c\n",
      "BEETS\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "1\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "Y\n",
      "c\n",
      "y\n",
      "y\n",
      "1\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "1.0\n",
      "y\n",
      "y\n",
      "Y\n",
      "BELL PEPPERS—IN GENERAL, or MIXED\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "Y\n",
      "d\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "BOK CHOY (aka CHINESE CABBAGE or PAK CHOI)\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "Y\n",
      "d\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "BRAGG LIQUID AMINOS\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "BROCCOLI\n",
      "y\n",
      "Y\n",
      "1\n",
      "y\n",
      "y\n",
      "1.0\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "1\n",
      "1\n",
      "1\n",
      "y\n",
      "1\n",
      "y\n",
      "Y\n",
      "y\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "y\n",
      "1\n",
      "1\n",
      "y\n",
      "BROCCOLINI\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "d\n",
      "BRUSSELS SPROUTS\n",
      "1.0\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "d\n",
      "BUTTER\n",
      "y\n",
      "y\n",
      "y\n",
      "1.0\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "d\n",
      "y\n",
      "y\n",
      "y\n",
      "CABBAGE, GREEN\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "CABBAGE, RED\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "CARAWAY SEEDS\n",
      "y\n",
      "y\n",
      "y\n",
      "c\n",
      "c\n",
      "y\n",
      "y\n",
      "d\n",
      "c\n",
      "1.0\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "1.0\n",
      "c\n",
      "y\n",
      "1.0\n",
      "c\n",
      "y\n",
      "y\n",
      "CARROTS\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "y\n",
      "y\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "y\n",
      "1\n",
      "c\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "c\n",
      "1\n",
      "y\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "y\n",
      "1\n",
      "c\n",
      "1\n",
      "c\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "y\n",
      "1.0\n",
      "1\n",
      "y\n",
      "y\n",
      "y\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "1\n",
      "y\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "y\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "c\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "y\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "2.0\n",
      "c\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "y\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "CASHEWS and CASHEW NUT BUTTER\n",
      "y\n",
      "y\n",
      "y\n",
      "c\n",
      "c\n",
      "y\n",
      "y\n",
      "c\n",
      "c\n",
      "1.0\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "1.0\n",
      "c\n",
      "y\n",
      "1.0\n",
      "c\n",
      "y\n",
      "y\n",
      "CAULIFLOWER\n",
      "y\n",
      "y\n",
      "y\n",
      "d\n",
      "c\n",
      "y\n",
      "y\n",
      "d\n",
      "c\n",
      "1.0\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "1.0\n",
      "c\n",
      "y\n",
      "1.0\n",
      "c\n",
      "y\n",
      "y\n",
      "CELERY\n",
      "1\n",
      "1\n",
      "y\n",
      "y\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "y\n",
      "c\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "1\n",
      "c\n",
      "y\n",
      "1.0\n",
      "y\n",
      "c\n",
      "d\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "y\n",
      "1\n",
      "y\n",
      "y\n",
      "y\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "y\n",
      "y\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "c\n",
      "1\n",
      "1\n",
      "1\n",
      "y\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "d\n",
      "1\n",
      "1.0\n",
      "1\n",
      "y\n",
      "1\n",
      "1.0\n",
      "CELERY ROOT (aka CELERIAC)\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "d\n",
      "y\n",
      "y\n",
      "y\n",
      "CHARD, e.g., RAINBOW, RED/RUBY, SWISS, or MIXED\n",
      "y\n",
      "y\n",
      "d\n",
      "y\n",
      "y\n",
      "d\n",
      "1.0\n",
      "1.0\n",
      "y\n",
      "y\n",
      "y\n",
      "d\n",
      "Y\n",
      "1\n",
      "1.0\n",
      "y\n",
      "1.0\n",
      "y\n",
      "d\n",
      "1.0\n",
      "CHEESE, CHEDDAR\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "1\n",
      "d\n",
      "1\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "1\n",
      "d\n",
      "y\n",
      "y\n",
      "y\n",
      "CHEESE, PARMESAN\n",
      "y\n",
      "y\n",
      "1.0\n",
      "1.0\n",
      "y\n",
      "y\n",
      "d\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "1.0\n",
      "CHESTNUTS\n",
      "y\n",
      "y\n",
      "1.0\n",
      "1.0\n",
      "y\n",
      "y\n",
      "1.0\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "1.0\n",
      "d\n",
      "CHIA SEEDS\n",
      "Y\n",
      "d\n",
      "1.0\n",
      "d\n",
      "d\n",
      "y\n",
      "c\n",
      "c\n",
      "Y\n",
      "y\n",
      "c\n",
      "1.0\n",
      "y\n",
      "d\n",
      "y\n",
      "c\n",
      "Y\n",
      "d\n",
      "Y\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "c\n",
      "y\n",
      "c\n",
      "c\n",
      "Y\n",
      "c\n",
      "d\n",
      "Y\n",
      "1.0\n",
      "c\n",
      "Y\n",
      "c\n",
      "d\n",
      "Y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "c\n",
      "c\n",
      "d\n",
      "y\n",
      "1\n",
      "d\n",
      "1.0\n",
      "y\n",
      "c\n",
      "c\n",
      "c\n",
      "Y\n",
      "Y\n",
      "d\n",
      "c\n",
      "Y\n",
      "y\n",
      "Y\n",
      "d\n",
      "d\n",
      "c\n",
      "y\n",
      "Y\n",
      "d\n",
      "d\n",
      "c\n",
      "c\n",
      "CHICKPEAS (aka GARBANZO BEANS)\n",
      "Y\n",
      "c\n",
      "1.0\n",
      "c\n",
      "c\n",
      "y\n",
      "c\n",
      "c\n",
      "Y\n",
      "y\n",
      "c\n",
      "1.0\n",
      "y\n",
      "c\n",
      "y\n",
      "d\n",
      "Y\n",
      "c\n",
      "Y\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "d\n",
      "y\n",
      "c\n",
      "c\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "1.0\n",
      "c\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "c\n",
      "c\n",
      "c\n",
      "y\n",
      "1\n",
      "c\n",
      "1.0\n",
      "y\n",
      "c\n",
      "c\n",
      "c\n",
      "Y\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "y\n",
      "Y\n",
      "c\n",
      "c\n",
      "c\n",
      "y\n",
      "Y\n",
      "c\n",
      "c\n",
      "c\n",
      "c\n",
      "CHILES, CHIPOTLE\n",
      "Y\n",
      "d\n",
      "1.0\n",
      "c\n",
      "c\n",
      "y\n",
      "c\n",
      "c\n",
      "Y\n",
      "y\n",
      "c\n",
      "1.0\n",
      "y\n",
      "c\n",
      "y\n",
      "c\n",
      "Y\n",
      "c\n",
      "Y\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "c\n",
      "y\n",
      "c\n",
      "c\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "1.0\n",
      "c\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "c\n",
      "c\n",
      "c\n",
      "y\n",
      "1\n",
      "c\n",
      "1.0\n",
      "y\n",
      "c\n",
      "c\n",
      "c\n",
      "Y\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "y\n",
      "Y\n",
      "c\n",
      "c\n",
      "c\n",
      "y\n",
      "Y\n",
      "c\n",
      "c\n",
      "c\n",
      "c\n",
      "CHILES, HABANERO\n",
      "Y\n",
      "c\n",
      "1.0\n",
      "c\n",
      "c\n",
      "y\n",
      "c\n",
      "c\n",
      "Y\n",
      "y\n",
      "c\n",
      "1.0\n",
      "y\n",
      "c\n",
      "y\n",
      "d\n",
      "Y\n",
      "d\n",
      "Y\n",
      "Y\n",
      "d\n",
      "d\n",
      "Y\n",
      "d\n",
      "y\n",
      "c\n",
      "c\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "1.0\n",
      "c\n",
      "Y\n",
      "c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n",
      "Y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "c\n",
      "c\n",
      "d\n",
      "y\n",
      "1\n",
      "c\n",
      "1.0\n",
      "y\n",
      "c\n",
      "c\n",
      "c\n",
      "Y\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "y\n",
      "Y\n",
      "d\n",
      "c\n",
      "c\n",
      "y\n",
      "Y\n",
      "d\n",
      "d\n",
      "c\n",
      "d\n",
      "CHILES, JALAPEÑO\n",
      "Y\n",
      "d\n",
      "1.0\n",
      "c\n",
      "c\n",
      "y\n",
      "d\n",
      "c\n",
      "Y\n",
      "y\n",
      "c\n",
      "1.0\n",
      "y\n",
      "c\n",
      "y\n",
      "d\n",
      "Y\n",
      "d\n",
      "Y\n",
      "Y\n",
      "d\n",
      "d\n",
      "Y\n",
      "d\n",
      "y\n",
      "c\n",
      "c\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "1.0\n",
      "d\n",
      "Y\n",
      "d\n",
      "d\n",
      "Y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "c\n",
      "d\n",
      "c\n",
      "y\n",
      "1\n",
      "c\n",
      "1.0\n",
      "y\n",
      "d\n",
      "d\n",
      "c\n",
      "Y\n",
      "Y\n",
      "c\n",
      "d\n",
      "Y\n",
      "y\n",
      "Y\n",
      "d\n",
      "d\n",
      "d\n",
      "y\n",
      "Y\n",
      "d\n",
      "c\n",
      "c\n",
      "d\n",
      "CHILES, SERRANO\n",
      "Y\n",
      "c\n",
      "1.0\n",
      "c\n",
      "d\n",
      "y\n",
      "d\n",
      "c\n",
      "Y\n",
      "y\n",
      "c\n",
      "1.0\n",
      "y\n",
      "c\n",
      "y\n",
      "D\n",
      "Y\n",
      "d\n",
      "Y\n",
      "Y\n",
      "c\n",
      "d\n",
      "Y\n",
      "c\n",
      "y\n",
      "c\n",
      "d\n",
      "Y\n",
      "d\n",
      "c\n",
      "Y\n",
      "1.0\n",
      "c\n",
      "Y\n",
      "c\n",
      "D\n",
      "Y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "d\n",
      "d\n",
      "D\n",
      "y\n",
      "1\n",
      "c\n",
      "1.0\n",
      "y\n",
      "d\n",
      "c\n",
      "c\n",
      "Y\n",
      "Y\n",
      "c\n",
      "d\n",
      "Y\n",
      "y\n",
      "Y\n",
      "d\n",
      "D\n",
      "d\n",
      "y\n",
      "Y\n",
      "d\n",
      "d\n",
      "d\n",
      "d\n",
      "CHILI PEPPER FLAKES\n",
      "Y\n",
      "c\n",
      "1.0\n",
      "c\n",
      "c\n",
      "y\n",
      "c\n",
      "c\n",
      "Y\n",
      "y\n",
      "c\n",
      "1.0\n",
      "y\n",
      "c\n",
      "y\n",
      "c\n",
      "Y\n",
      "c\n",
      "Y\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "c\n",
      "y\n",
      "c\n",
      "c\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "1.0\n",
      "c\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "c\n",
      "c\n",
      "c\n",
      "y\n",
      "1\n",
      "c\n",
      "1.0\n",
      "y\n",
      "c\n",
      "c\n",
      "c\n",
      "Y\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "y\n",
      "Y\n",
      "c\n",
      "c\n",
      "c\n",
      "y\n",
      "Y\n",
      "c\n",
      "c\n",
      "c\n",
      "c\n",
      "CHILI POWDER\n",
      "Y\n",
      "c\n",
      "1.0\n",
      "c\n",
      "c\n",
      "y\n",
      "c\n",
      "c\n",
      "Y\n",
      "y\n",
      "c\n",
      "1.0\n",
      "y\n",
      "c\n",
      "y\n",
      "c\n",
      "Y\n",
      "c\n",
      "Y\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "c\n",
      "y\n",
      "c\n",
      "c\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "1.0\n",
      "c\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "c\n",
      "c\n",
      "c\n",
      "y\n",
      "1\n",
      "c\n",
      "1.0\n",
      "y\n",
      "c\n",
      "c\n",
      "c\n",
      "Y\n",
      "Y\n",
      "c\n",
      "c\n",
      "Y\n",
      "y\n",
      "Y\n",
      "c\n",
      "c\n",
      "c\n",
      "y\n",
      "Y\n",
      "c\n",
      "c\n",
      "c\n",
      "c\n",
      "CHIVES\n",
      "1\n",
      "y\n",
      "1.0\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "1\n",
      "1.0\n",
      "y\n",
      "c\n",
      "Y\n",
      "1.0\n",
      "Y\n",
      "y\n",
      "y\n",
      "Y\n",
      "c\n",
      "y\n",
      "y\n",
      "y\n",
      "1.0\n",
      "1\n",
      "y\n",
      "1\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "1.0\n",
      "CHIVES, GARLIC (aka CHINESE CHIVES)\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "1.0\n",
      "d\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "d\n",
      "y\n",
      "y\n",
      "y\n",
      "1.0\n",
      "CILANTRO (aka CHINESE PARSLEY or FRESH CORIANDER LEAF)\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "COCONUT BUTTER\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "COCONUT WATER\n",
      "Y\n",
      "y\n",
      "y\n",
      "Y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "Y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "Y\n",
      "Y\n",
      "y\n",
      "y\n",
      "d\n",
      "Y\n",
      "y\n",
      "CORN\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "1.0\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "1.0\n",
      "y\n",
      "CORNMEAL and POLENTA (see also GRITS)\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "1.0\n",
      "y\n",
      "CUMIN\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "c\n",
      "y\n",
      "1.0\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "c\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "d\n",
      "y\n",
      "y\n",
      "Y\n",
      "Y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "1.0\n",
      "Y\n",
      "y\n",
      "Y\n",
      "y\n",
      "Y\n",
      "Y\n",
      "1.0\n",
      "y\n",
      "y\n",
      "DILL SEEDS (see also DILL and DILL WEED)\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "Y\n",
      "y\n",
      "DILL WEED (see also DILL and DILL SEEDS)\n",
      "1.0\n",
      "y\n",
      "d\n",
      "y\n",
      "1.0\n",
      "y\n",
      "1.0\n",
      "y\n",
      "y\n",
      "y\n",
      "c\n",
      "c\n",
      "y\n",
      "Y\n",
      "1\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "Y\n",
      "1.0\n",
      "c\n",
      "EGGPLANT (aka AUBERGINE)\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "ENDIVE (aka BELGIAN ENDIVE)\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "Y\n",
      "y\n",
      "y\n",
      "y\n",
      "d\n",
      "Y\n",
      "FENNEL\n",
      "Y\n",
      "1.0\n",
      "y\n",
      "Y\n",
      "1.0\n",
      "y\n",
      "c\n",
      "1.0\n",
      "y\n",
      "y\n",
      "Y\n",
      "1\n",
      "y\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "y\n",
      "y\n",
      "1\n",
      "y\n",
      "1\n",
      "y\n",
      "Y\n",
      "Y\n",
      "1.0\n",
      "1\n",
      "y\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "y\n",
      "1\n",
      "y\n",
      "Y\n",
      "1\n",
      "y\n",
      "y\n",
      "2.0\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "y\n",
      "1.0\n",
      "y\n",
      "1\n",
      "1\n",
      "1.0\n",
      "y\n",
      "y\n",
      "1.0\n",
      "1.0\n",
      "y\n",
      "1.0\n",
      "1\n",
      "y\n",
      "Y\n",
      "y\n",
      "1.0\n",
      "y\n",
      "y\n",
      "1\n",
      "1.0\n",
      "1\n",
      "y\n",
      "c\n",
      "1.0\n",
      "c\n",
      "y\n",
      "y\n",
      "y\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "y\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "1\n",
      "y\n",
      "1.0\n",
      "1.0\n",
      "y\n",
      "y\n",
      "1\n",
      "y\n",
      "1.0\n",
      "y\n",
      "1\n",
      "y\n",
      "c\n",
      "1\n",
      "y\n",
      "y\n",
      "y\n",
      "1.0\n",
      "1\n",
      "y\n",
      "1\n",
      "y\n",
      "1\n",
      "1\n",
      "1\n",
      "y\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "y\n",
      "c\n",
      "y\n",
      "1.0\n",
      "y\n",
      "1\n",
      "y\n",
      "1\n",
      "y\n",
      "1.0\n",
      "y\n",
      "1.0\n",
      "1.0\n",
      "FENNEL FRONDS (or LEAVES)\n",
      "1.0\n",
      "d\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "1.0\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "FENNEL SEEDS\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "y\n",
      "FENUGREEK\n",
      "Y\n",
      "1.0\n",
      "y\n",
      "1.0\n",
      "y\n",
      "c\n",
      "1.0\n",
      "y\n",
      "1\n",
      "y\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "1\n",
      "y\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "y\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "y\n",
      "Y\n",
      "1.0\n",
      "y\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "y\n",
      "y\n",
      "y\n",
      "1.0\n",
      "1\n",
      "c\n",
      "1.0\n",
      "y\n",
      "y\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "1\n",
      "y\n",
      "1.0\n",
      "1.0\n",
      "y\n",
      "1\n",
      "1.0\n",
      "y\n",
      "1\n",
      "1\n",
      "y\n",
      "y\n",
      "1.0\n",
      "1\n",
      "y\n",
      "y\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "y\n",
      "1.0\n",
      "1\n",
      "1\n",
      "y\n",
      "1.0\n",
      "1.0\n",
      "FIDDLEHEAD FERNS\n"
     ]
    }
   ],
   "source": [
    "for i, row in term_name_marks.iterrows():\n",
    "    for val in row:\n",
    "        if val != '':\n",
    "            print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extracting \"pairs with\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term_name_matches_raw = pd.read_csv(os.path.join(root_path, 'DATA/term_name_matches.csv'))\n",
    "# term_name_matches = term_name_matches_raw.replace(['0', '1', '2', '3', '4', '5', 0, 1, 2, 3, 4, 5, float('nan')], '')\n",
    "# term_name_matches_lower = term_name_matches.replace('Y', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a dataframe with name and a list of pairing terms for each ingredient\n",
    "# pairing_data = pd.DataFrame({\n",
    "#     'name': salad_data['name'],\n",
    "#     'pairs_with_terms': ingredient_pairs_with_terms\n",
    "# })\n",
    "\n",
    "# def get_pairs_with_names(row):\n",
    "# #     print(row['name'], type(row['name']))\n",
    "#     lower_names = []\n",
    "#     upper_names = []\n",
    "#     for term in row['pairs_with_terms']:\n",
    "#         if term in term_name_matches.columns.values.tolist():\n",
    "#             lower_names += term_name_matches[term_name_matches[term] == 'y']['name'].values.tolist()\n",
    "#             upper_names += term_name_matches[term_name_matches[term] == 'Y']['name'].values.tolist()\n",
    "#         else:\n",
    "#             print('OH NO didnt find term:', term)\n",
    "# #     for name in lower_names + upper_names:\n",
    "# #         if name == row['name']:\n",
    "# #             print('DUPLICATE')\n",
    "# #     print(lower_names, upper_names)\n",
    "#     row['lower_pairs_with_names'] = [lower_name for lower_name in lower_names if lower_name != row['name']]\n",
    "#     row['upper_pairs_with_names'] = [upper_name for upper_name in upper_names if upper_name != row['name']]\n",
    "#     row['all_pairs_with_names'] = lower_names + upper_names\n",
    "#     return row\n",
    "\n",
    "# pairing_data = pairing_data.apply(get_pairs_with_names, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_name_matches_raw = pd.read_csv(os.path.join(root_path, 'DATA/term_name_matches_specific.csv'))\n",
    "term_name_matches = term_name_matches_raw.replace(['0', '1', '2', '3', '4', '5', 0, 1, 2, 3, 4, 5, float('nan')], '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a dataframe with name and a list of pairing terms for each ingredient\n",
    "# pairing_data = pd.DataFrame({\n",
    "#     'name': salad_data['name'],\n",
    "#     'pairs_with_terms': ingredient_pairs_with_terms\n",
    "# })\n",
    "\n",
    "# def get_pairs_with_names(row):\n",
    "# #     print(row['name'], type(row['name']))\n",
    "#     lower_category_names = []\n",
    "#     lower_direct_names = []\n",
    "#     upper_category_names = []\n",
    "#     upper_direct_names = []\n",
    "#     for term in row['pairs_with_terms']:\n",
    "#         if term in term_name_matches.columns.values.tolist():\n",
    "#             lower_category_names += term_name_matches[term_name_matches[term] == 'c']['name'].values.tolist()\n",
    "#             lower_direct_names += term_name_matches[term_name_matches[term] == 'd']['name'].values.tolist()\n",
    "#             upper_category_names += term_name_matches[term_name_matches[term] == 'C']['name'].values.tolist()\n",
    "#             upper_direct_names += term_name_matches[term_name_matches[term] == 'D']['name'].values.tolist()\n",
    "#         else:\n",
    "#             pass\n",
    "# #             print('OH NO didnt find term:', term)\n",
    "#     row['lower_category_pairs_with_names'] = list(set([lower_category_name for lower_category_name in lower_category_names if lower_category_name != row['name']]))\n",
    "#     row['lower_direct_pairs_with_names'] = list(set([lower_direct_name for lower_direct_name in lower_direct_names if lower_direct_name != row['name']]))\n",
    "#     row['upper_category_pairs_with_names'] = list(set([upper_category_name for upper_category_name in upper_category_names if upper_category_name != row['name']]))\n",
    "#     row['upper_direct_pairs_with_names'] = list(set([upper_direct_name for upper_direct_name in upper_direct_names if upper_direct_name != row['name']]))\n",
    "#     row['lower_pairs_with_names'] = list(set(row['lower_category_pairs_with_names'] + row['lower_direct_pairs_with_names']))\n",
    "#     row['upper_pairs_with_names'] = list(set(row['upper_category_pairs_with_names'] + row['upper_direct_pairs_with_names']))\n",
    "#     row['all_pairs_with_names'] = list(set(row['lower_pairs_with_names'] + row['upper_pairs_with_names']))\n",
    "    \n",
    "#     row['lc_sorted_pairs'] = tuple(sorted(row['lower_category_pairs_with_names']))\n",
    "#     row['ld_sorted_pairs'] = tuple(sorted(row['lower_direct_pairs_with_names']))\n",
    "#     row['uc_sorted_pairs'] = tuple(sorted(row['upper_category_pairs_with_names']))\n",
    "#     row['ud_sorted_pairs'] = tuple(sorted(row['upper_direct_pairs_with_names']))\n",
    "#     row['l_sorted_pairs'] = tuple(sorted(row['lower_pairs_with_names']))\n",
    "#     row['u_sorted_pairs'] = tuple(sorted(row['upper_pairs_with_names']))\n",
    "#     row['a_sorted_pairs'] = tuple(sorted(row['all_pairs_with_names']))\n",
    "#     return row\n",
    "\n",
    "# pairing_data = pairing_data.apply(get_pairs_with_names, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE PAIRING DATA MATRIX (names x names)\n",
    "# takes a few minutes\n",
    "\n",
    "pairing_data = pd.DataFrame({\n",
    "    'name': salad_data['name'],\n",
    "    'pairs_with_terms': ingredient_pairs_with_terms\n",
    "})\n",
    "\n",
    "for name in salad_data['name']:\n",
    "    pairing_data[name] = pd.Series(['']*len(salad_data['name']))\n",
    "\n",
    "def get_pairs_with_names(row):\n",
    "#     print(row['name'], type(row['name']))\n",
    "    lower_category_names = []\n",
    "    lower_direct_names = []\n",
    "    upper_category_names = []\n",
    "    upper_direct_names = []\n",
    "    for term in row['pairs_with_terms']:\n",
    "        if term in term_name_matches.columns.values.tolist():\n",
    "            lower_category_names += term_name_matches[term_name_matches[term] == 'c']['name'].values.tolist()\n",
    "            lower_direct_names += term_name_matches[term_name_matches[term] == 'd']['name'].values.tolist()\n",
    "            upper_category_names += term_name_matches[term_name_matches[term] == 'C']['name'].values.tolist()\n",
    "            upper_direct_names += term_name_matches[term_name_matches[term] == 'D']['name'].values.tolist()\n",
    "        else:\n",
    "            pass\n",
    "#             print('OH NO didnt find term:', term)\n",
    "    \n",
    "    for lower_category_name in lower_category_names:\n",
    "        row[lower_category_name] = 'c'\n",
    "    for lower_direct_name in lower_direct_names:\n",
    "        row[lower_direct_name] = 'd'\n",
    "    for upper_category_name in upper_category_names:\n",
    "        row[upper_category_name] = 'C'\n",
    "    for upper_direct_name in upper_direct_names:\n",
    "        row[upper_direct_name] = 'D'\n",
    "    \n",
    "#     row['lower_category_pairs_with_names'] = list(set([lower_category_name for lower_category_name in lower_category_names if lower_category_name != row['name']]))\n",
    "#     row['lower_direct_pairs_with_names'] = list(set([lower_direct_name for lower_direct_name in lower_direct_names if lower_direct_name != row['name']]))\n",
    "#     row['upper_category_pairs_with_names'] = list(set([upper_category_name for upper_category_name in upper_category_names if upper_category_name != row['name']]))\n",
    "#     row['upper_direct_pairs_with_names'] = list(set([upper_direct_name for upper_direct_name in upper_direct_names if upper_direct_name != row['name']]))\n",
    "#     row['lower_pairs_with_names'] = list(set(row['lower_category_pairs_with_names'] + row['lower_direct_pairs_with_names']))\n",
    "#     row['upper_pairs_with_names'] = list(set(row['upper_category_pairs_with_names'] + row['upper_direct_pairs_with_names']))\n",
    "#     row['all_pairs_with_names'] = list(set(row['lower_pairs_with_names'] + row['upper_pairs_with_names']))\n",
    "    \n",
    "#     row['lc_sorted_pairs'] = tuple(sorted(row['lower_category_pairs_with_names']))\n",
    "#     row['ld_sorted_pairs'] = tuple(sorted(row['lower_direct_pairs_with_names']))\n",
    "#     row['uc_sorted_pairs'] = tuple(sorted(row['upper_category_pairs_with_names']))\n",
    "#     row['ud_sorted_pairs'] = tuple(sorted(row['upper_direct_pairs_with_names']))\n",
    "#     row['l_sorted_pairs'] = tuple(sorted(row['lower_pairs_with_names']))\n",
    "#     row['u_sorted_pairs'] = tuple(sorted(row['upper_pairs_with_names']))\n",
    "#     row['a_sorted_pairs'] = tuple(sorted(row['all_pairs_with_names']))\n",
    "    return row\n",
    "\n",
    "pairing_data = pairing_data.apply(get_pairs_with_names, axis=1)\n",
    "pairing_data.replace(float('nan'), '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYNC PAIRING DATA MATRIX (make sure [a][b] agrees with [b][a])\n",
    "\n",
    "for index_1, name_1 in enumerate(pairing_data['name'].values.tolist()):\n",
    "    for index_2, name_2 in enumerate(pairing_data['name'].values.tolist()):\n",
    "        value_1 = pairing_data[name_1][index_2]\n",
    "        value_2 = pairing_data[name_2][index_1]\n",
    "        \n",
    "        if name_1 == name_2:\n",
    "            proper_value = ''\n",
    "        elif value_1 == 'D' or value_2 == 'D':\n",
    "            proper_value = 'D'\n",
    "        elif value_1 == 'C' or value_2 == 'C':\n",
    "            proper_value = 'C'\n",
    "        elif value_1 == 'd' or value_2 == 'd':\n",
    "            proper_value = 'd'\n",
    "        elif value_1 == 'c' or value_2 == 'c':\n",
    "            proper_value = 'c'\n",
    "        else:\n",
    "            proper_value = ''\n",
    "        \n",
    "        pairing_data[name_1][index_2] = proper_value\n",
    "        pairing_data[name_2][index_1] = proper_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPRESENT PAIRING DATA AS LISTS\n",
    "\n",
    "def get_pairs_with_names(row):\n",
    "    lower_category_name = pairing_data[pairing_data[row['name']] == 'c']['name'].values.tolist()\n",
    "    lower_direct_name = pairing_data[pairing_data[row['name']] == 'd']['name'].values.tolist()\n",
    "    upper_category_name = pairing_data[pairing_data[row['name']] == 'C']['name'].values.tolist()\n",
    "    upper_direct_name = pairing_data[pairing_data[row['name']] == 'D']['name'].values.tolist()\n",
    "    \n",
    "    row['lower_category_names'] = pairing_data[pairing_data[row['name']] == 'c']['name'].values.tolist()\n",
    "    row['lower_direct_names'] = pairing_data[pairing_data[row['name']] == 'd']['name'].values.tolist()\n",
    "    row['upper_category_names'] = pairing_data[pairing_data[row['name']] == 'C']['name'].values.tolist()\n",
    "    row['upper_direct_names'] = pairing_data[pairing_data[row['name']] == 'D']['name'].values.tolist()\n",
    "    row['lower_names'] = row['lower_category_names'] + row['lower_direct_names']\n",
    "    row['upper_names'] = row['upper_category_names'] + row['upper_direct_names']\n",
    "    row['all_names'] = row['lower_names'] + row['upper_names']\n",
    "    \n",
    "    return row\n",
    "\n",
    "pairing_data = pairing_data.apply(get_pairs_with_names, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairing_data.to_csv(os.path.join(root_path, 'DATA/pairing_data.csv'), index=False)\n",
    "# pairing_data = pd.read_csv(os.path.join(root_path, 'DATA/pairing_data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating \"clashes with\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_name_clashes_blank = salad_data[['name', 'protein_cheese_sub', 'salad_allium', 'fruit', 'veg']].copy()\n",
    "# names = salad_data['name'].values.tolist()\n",
    "\n",
    "# for i, col_name in enumerate(names):\n",
    "#     name_name_clashes_blank[col_name] = pd.Series(['x']*(i+1) + ['']*(len(names)-(i+1)))\n",
    "\n",
    "# name_name_clashes_blank.to_csv(os.path.join(root_path, 'DATA/name_name_clashes_blank.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_name_clashes_input = pd.read_csv(os.path.join(root_path, 'DATA/name_name_clashes_input.csv'))\n",
    "name_name_clashes_input = name_name_clashes_input.replace([float('nan'), 'x'], '')\n",
    "columns = ['name'] + name_name_clashes_input['name'].values.tolist()\n",
    "name_name_clashes_input = name_name_clashes_input[columns]\n",
    "\n",
    "def get_clashes_with_data(row):\n",
    "    data = pd.Series([])\n",
    "#     print(row.index.values.tolist())\n",
    "    name = row['name']\n",
    "    data['name'] = name\n",
    "    \n",
    "    lower_names = name_name_clashes_input['name'][name_name_clashes_input[name] == 'y'].values.tolist()\n",
    "    upper_names = name_name_clashes_input['name'][name_name_clashes_input[name] == 'Y'].values.tolist()\n",
    "    if 'y' in lower_names:\n",
    "        print(lower_names)\n",
    "    \n",
    "    for name in name_name_clashes_input['name']:\n",
    "#         if name in ['y', 'Y']:\n",
    "#             print(name)\n",
    "        if row[name] == 'y':\n",
    "            lower_names.append(name)\n",
    "        elif row[name] == 'Y':\n",
    "            upper_names.append(name)\n",
    "    \n",
    "    lower_names = list(set(lower_names))\n",
    "    upper_names = list(set(upper_names))\n",
    "    \n",
    "    data['lower_clashes_with_names'] = lower_names\n",
    "    data['upper_clashes_with_names'] = upper_names\n",
    "    data['all_clashes_with_names'] = list(set(lower_names + upper_names)) # shouldn't be overlap here, but hey\n",
    "    \n",
    "    data['lower_clashes_with_pairs'] = [tuple(sorted([name, lower_name])) for lower_name in data['lower_clashes_with_names']]\n",
    "    data['upper_clashes_with_pairs'] = [tuple(sorted([name, lower_name])) for lower_name in data['upper_clashes_with_names']]\n",
    "    data['all_clashes_with_pairs'] = [tuple(sorted([name, lower_name])) for lower_name in data['all_clashes_with_names']]\n",
    "    \n",
    "    return data\n",
    "\n",
    "clashes_with_data = name_name_clashes_input.apply(get_clashes_with_data, axis=1)\n",
    "            \n",
    "# # for row in name_name_clashes_input.iterrows():\n",
    "# clashes_with_data = pd.DataFrame({'name': salad_data['name']})\n",
    "# for i, row in clashes_with_data.iterrows():\n",
    "# #     print(row, type(row))\n",
    "#     name = row['name']\n",
    "#     row['lower_clashes_with'] = name_name_clashes_input[name][name_name_clashes_input[name] == 'y']\n",
    "#     row['upper_clashes_with'] = name_name_clashes_input[name][name_name_clashes_input[name] == 'Y']\n",
    "#     row['all_clashes_with'] = row['lower_clashes_with'] + row['upper_clashes_with']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lower_clashes_with_pairs = list(set(clashes_with_data['lower_clashes_with_pairs'].sum()))\n",
    "all_upper_clashes_with_pairs = list(set(clashes_with_data['upper_clashes_with_pairs'].sum()))\n",
    "all_clashes_with_pairs = list(set(clashes_with_data['all_clashes_with_pairs'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Salad recipe generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "salad_greens = salad_data[salad_data['salad_green'] == 'y']\n",
    "\n",
    "salad_extras = salad_data[salad_data['salad_extra'] == 'y']\n",
    "salad_extra_veg = salad_data[(salad_data['veg'] == 'y') & (salad_data['salad_extra'] == 'y')]\n",
    "salad_extra_fruits = salad_data[(salad_data['fruit'] == 'y') & (salad_data['salad_extra'] == 'y')]\n",
    "salad_extra_nuts = salad_data[(salad_data['protein_seed'] == 'y') & (salad_data['salad_extra'] == 'y')]\n",
    "salad_extra_seeds = salad_data[(salad_data['protein_nut'] == 'y') & (salad_data['salad_extra'] == 'y')]\n",
    "salad_extra_tomatoes = salad_data[salad_data['salad_extra_tomato'] == 'y']\n",
    "salad_extra_olives = salad_data[salad_data['salad_extra_olive'] == 'y']\n",
    "salad_extra_cheeses = salad_data[salad_data['salad_extra_cheese'] == 'y']\n",
    "salad_extra_eggs = salad_data[salad_data['salad_extra_egg'] == 'y']\n",
    "salad_extra_croutons = salad_data[salad_data['salad_extra_crouton'] == 'y']\n",
    "\n",
    "salad_dressing_oils = salad_data[salad_data['salad_dressing_oil'] == 'y']\n",
    "salad_dressing_vinegars = salad_data[salad_data['salad_dressing_vinegar'] == 'y']\n",
    "salad_dressing_salts = salad_data[salad_data['salad_dressing_salt'] == 'y']\n",
    "salad_dressing_peppers = salad_data[salad_data['salad_dressing_pepper'] == 'y']\n",
    "salad_dressing_garlics = salad_data[salad_data['salad_dressing_garlic'] == 'y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Best of many"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install networkx\n",
    "# !pip install pyvis\n",
    "\n",
    "import networkx as nx\n",
    "from pyvis import network as net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP AVERAGE SHORTEST PATH SCORE 3.2744186046511627\n",
      "TOP PAIR STRENGTH SCORE 3.4434782608695653\n",
      "TOP ALL CLASHING PAIRS SCORE -0.0\n",
      "TOP FLAVOR BALANCE SCORE 0.4166666666666665\n",
      "TOP TEXTURE BALANCE SCORE 0.37499999999999983\n",
      "TOP FOOD GROUP BALANCE SCORE 1.5\n",
      "TOP_SCORE 9.009563532187395\n",
      "False True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"500px\"\n",
       "            height=\"500px\"\n",
       "            src=\"top_net.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0ef97acd68>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IDEAS\n",
    "    # savory v sweet templates (avoid eggs/mushroom/hard veg w fruit...)\n",
    "    # get eg working, weight it as 2\n",
    "    # start out w 1 base salad, extra (randomly selected from vip list), then branch out\n",
    "    # control for eg lots of types of citrus, alliums\n",
    "    # mark strong flavors, treat them separately\n",
    "    # select main ingredients from each category that go with each other, then branch out from each, weighting traditionally at the end\n",
    "    # work off of pairs_with data for categories, while at same time picking categories then within categories (to account for eg allium bias)\n",
    "    # *only* match eg.s with specifically named; also, consider not matching categories the weird way\n",
    "    # add a bonus if category of ingredient pairs well with other ingredients in salad (meh)\n",
    "    # add in dressing garlics, when applicable\n",
    "    # CONSIDER\n",
    "        # replacing average net dist with something like, edges/possible edges\n",
    "\n",
    "# TODO\n",
    "    # add dried cranberries to salad stuffs?\n",
    "    # maybe some other dried fruit? maybe not.\n",
    "    \n",
    "# UI PRIORITIES\n",
    "    # speed\n",
    "    # translate names to common (e.g. ALLMONDS (AND UNSWEETENED ALMOND BUTTER) -> Almonds, sliced)\n",
    "    # maybe consisder one of those spokes-of-wheel charts to display stats/scores\n",
    "    \n",
    "# RECIPE DETAILS\n",
    "    # maybe suggest diluting e.g. sesame oil w regular olive oil\n",
    "    \n",
    "# ==================================================================================================================\n",
    "# ==================================================================================================================\n",
    "\n",
    "# ALGORITHM A (best of many)\n",
    "top_score = 0\n",
    "for i in range(300):\n",
    "    n_subgraphs = 2\n",
    "    while n_subgraphs > 1: # keep shuffling until you get a well connected graph\n",
    "        n_greens = random.randrange(2, 4)\n",
    "        n_extras = random.randrange(2, 6)\n",
    "        n_dressing_oils = 1\n",
    "        n_dressing_vinegars = 1\n",
    "        n_dressing_salts = 1\n",
    "        n_dressing_peppers = 1\n",
    "        # n_dressing_garlics = random.randrange(0, 2) # maybe make presence dependent on the rest. or, just leave out for now.\n",
    "        \n",
    "        selected_greens = salad_greens.sample(n_greens)\n",
    "        selected_extras = salad_extras.sample(n_extras)\n",
    "        selected_dressing_oils = salad_dressing_oils.sample(n_dressing_oils)\n",
    "        selected_dressing_vinegars = salad_dressing_vinegars.sample(n_dressing_vinegars)\n",
    "        selected_dressing_salts = salad_dressing_salts.sample(n_dressing_salts)\n",
    "        selected_dressing_peppers = salad_dressing_peppers.sample(n_dressing_peppers)\n",
    "        selected_ingredients = selected_greens.append(selected_extras).append(selected_dressing_oils).append(selected_dressing_vinegars).append(selected_dressing_salts).append(selected_dressing_peppers)\n",
    "\n",
    "        lower_category_pairs = []\n",
    "        lower_direct_pairs = []\n",
    "        upper_category_pairs = []\n",
    "        upper_direct_pairs = []\n",
    "        ingredients_list = selected_ingredients['name'].values.tolist()\n",
    "        already_checked = []\n",
    "        for ingredient_name in ingredients_list:\n",
    "            for lc_name in pairing_data['lower_category_names'][pairing_data['name'] == ingredient_name].iloc[0]:\n",
    "                if lc_name in ingredients_list and not lc_name in already_checked:\n",
    "                    lower_category_pairs.append([ingredient_name, lc_name])\n",
    "            for ld_name in pairing_data['lower_direct_names'][pairing_data['name'] == ingredient_name].iloc[0]:\n",
    "                if ld_name in ingredients_list and not ld_name in already_checked:\n",
    "                    lower_direct_pairs.append([ingredient_name, ld_name])\n",
    "            for uc_name in pairing_data['upper_category_names'][pairing_data['name'] == ingredient_name].iloc[0]:\n",
    "                if uc_name in ingredients_list and not uc_name in already_checked:\n",
    "                    upper_category_pairs.append([ingredient_name, uc_name])\n",
    "            for ud_name in pairing_data['upper_direct_names'][pairing_data['name'] == ingredient_name].iloc[0]:\n",
    "                if ud_name in ingredients_list and not ud_name in already_checked:\n",
    "                    upper_direct_pairs.append([ingredient_name, ud_name])\n",
    "            already_checked.append(ingredient_name)\n",
    "\n",
    "        lower_pairs = lower_category_pairs + lower_direct_pairs\n",
    "        upper_pairs = upper_category_pairs + upper_direct_pairs\n",
    "        all_pairs = lower_pairs + upper_pairs\n",
    "        \n",
    "#         all_pairs_sp = [tuple(sorted(pair)) for pair in all_pairs]\n",
    "#         print(len(all_pairs_sp), len(list(set(all_pairs_sp))))\n",
    "\n",
    "#         print('INGREDIENTS', ingredients_list)\n",
    "#         print()\n",
    "#         print('LC PAIRS', lower_category_pairs)\n",
    "#         print()\n",
    "#         print()\n",
    "\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(selected_ingredients['name'].values.tolist())\n",
    "        G.add_edges_from(all_pairs)\n",
    "        n_subgraphs = len(list(nx.connected_component_subgraphs(G)))\n",
    "            \n",
    "    score = 0\n",
    "\n",
    "# SIMPLER ALTERNATIVE: bonus for proportion of actual pairs over possible pairs? could then combine with pair strength bonus?\n",
    "# PAIRING DENSITY BONUS ============================================================================================\n",
    "    # ranges from roughly (.1 to 1) * 4\n",
    "    average_shortest_path_length = nx.average_shortest_path_length(G)\n",
    "    average_shortest_path_score = 2.5 / average_shortest_path_length - 1.1\n",
    "#     print(average_shortest_path_score)\n",
    "    score += average_shortest_path_score * 4    \n",
    "    \n",
    "# # UPPER PAIRING BONUS ==============================================================================================\n",
    "#     # ranges from roughly (.25 to 1) * 3\n",
    "#     upper_proportion_score = len(upper_pairs) / len(all_pairs) * 2.5 # messed with this, not sure if it still works\n",
    "# #     print(upper_proportion_score)\n",
    "# #     print(len(upper_pairs), len(lower_pairs), len(all_pairs))\n",
    "# #     print()\n",
    "#     score += upper_proportion_score * 3\n",
    "\n",
    "# PAIR STRENGTH BONUS ==============================================================================================\n",
    "    # ranges from roughly (0 to 1) * 3\n",
    "\n",
    "    # I'm thinking of 'lower category' as default, and awarding points for steps up from that\n",
    "    ld_bonus = 1*len(lower_direct_pairs)\n",
    "    uc_bonus = 2*len(upper_category_pairs)\n",
    "    ud_bonus = 5*len(upper_direct_pairs)\n",
    "    pair_strength_score = .6*(ld_bonus + uc_bonus + ud_bonus)/len(all_pairs) # otherwise would tend toward large salads\n",
    "#     print('LC', len(lower_category_pairs))\n",
    "#     print('LD', len(lower_direct_pairs))\n",
    "#     print('UC', len(upper_category_pairs))\n",
    "#     print('UD', len(upper_direct_pairs))\n",
    "#     print('SCORE', pair_strength_score)\n",
    "#     print()\n",
    "    score += pair_strength_score * 3\n",
    "\n",
    "# important but easy to avoid, so not weighted too heavily\n",
    "# CLASH PENALTY ====================================================================================================\n",
    "    # ranges from roughly (0 to 1) * -1.5\n",
    "    all_clashing_pairs = []\n",
    "    selected_ingredients_list = selected_ingredients['name'].values.tolist()\n",
    "    for name in selected_ingredients_list:\n",
    "        names_that_clash_with_name = clashes_with_data['all_clashes_with_names'][clashes_with_data['name'] == name].iloc[0]\n",
    "        all_clashing_names = set(selected_ingredients_list).intersection(set(names_that_clash_with_name)) # selected names that clash with this selected name\n",
    "        all_clashing_pairs += [tuple(sorted([name, all_clashing_name])) for all_clashing_name in all_clashing_names]\n",
    "\n",
    "    all_clashing_pairs = list(set(all_clashing_pairs))\n",
    "    all_clashing_pairs_score = len(list(all_clashing_pairs)) / 4\n",
    "    score += len(all_clashing_pairs) * -1.5\n",
    "\n",
    "# # FRUIT BONUS ======================================================================================================\n",
    "#     # ranges from roughly (0 to 3) * .1\n",
    "#     n_fruit = len(selected_ingredients[selected_ingredients['fruit'] == 'y'])\n",
    "#     score += n_fruit * .1\n",
    "    \n",
    "# # NUT SEED BONUS ===================================================================================================    \n",
    "#     # ranges from roughly (0 to 2) * .15\n",
    "#     n_nut_seed = len(selected_ingredients[selected_ingredients['protein_nut_seed'] == 'y'])\n",
    "#     score += n_nut_seed * .15\n",
    "\n",
    "# FLAVOR BALANCE BONUS =============================================================================================\n",
    "    # ranges from roughly (0 to 1) * 1\n",
    "    n_sweet_lower = len(selected_ingredients[selected_ingredients['sweet'] == 'y'])\n",
    "    n_sweet_upper = len(selected_ingredients[selected_ingredients['sweet'] == 'Y'])\n",
    "    n_salty_lower = len(selected_ingredients[selected_ingredients['salty'] == 'y'])\n",
    "    n_salty_upper = len(selected_ingredients[selected_ingredients['salty'] == 'Y'])\n",
    "    n_sour_lower = len(selected_ingredients[selected_ingredients['sour'] == 'y'])\n",
    "    n_sour_upper = len(selected_ingredients[selected_ingredients['sour'] == 'Y'])\n",
    "    n_savory_lower = len(selected_ingredients[selected_ingredients['savory'] == 'y'])\n",
    "    n_savory_upper = len(selected_ingredients[selected_ingredients['savory'] == 'Y'])\n",
    "    n_bitter_lower = len(selected_ingredients[selected_ingredients['bitter'] == 'y'])\n",
    "    n_bitter_upper = len(selected_ingredients[selected_ingredients['bitter'] == 'Y'])\n",
    "    n_spicy_lower = len(selected_ingredients[selected_ingredients['spicy'] == 'y'])\n",
    "    n_spicy_upper = len(selected_ingredients[selected_ingredients['spicy'] == 'Y'])\n",
    "    \n",
    "    # each varies from roughly .5 to 1\n",
    "    sweet_score = (n_sweet_lower/2 + n_sweet_upper)/5\n",
    "    salty_score = (n_salty_lower/2 + n_salty_upper)*2/5\n",
    "    sour_score = (n_sour_lower/2 + n_sour_upper)*2/5\n",
    "    savory_score = (n_savory_lower/2 + n_savory_upper)*3/5\n",
    "    bitter_score = (n_bitter_lower/2 + n_bitter_upper)*3/5\n",
    "    spicy_score = (n_spicy_lower/2 + n_spicy_upper)*2/5\n",
    "    \n",
    "    flavor_balance_score = 5 / (1 + abs(1-sweet_score) + abs(1-salty_score) + abs(1-sour_score) + abs(1-savory_score) + abs(1-spicy_score)) - 1.25\n",
    "#     print(flavor_balance_score)\n",
    "    \n",
    "    score += flavor_balance_score\n",
    "#     print(sweet_score, salty_score, sour_score, savory_score, bitter_score, spicy_score)\n",
    "#     print()\n",
    "    \n",
    "#     print(n_sweet_lower, n_sweet_upper)\n",
    "#     print(n_salty_lower, n_salty_upper)\n",
    "#     print(n_sour_lower, n_sour_upper)\n",
    "#     print(n_savory_lower, n_savory_upper)\n",
    "#     print(n_bitter_lower, n_bitter_upper)\n",
    "#     print(n_spicy_lower, n_spicy_upper)\n",
    "#     print()\n",
    "\n",
    "# TEXTURE BALANCE BONUS ============================================================================================\n",
    "    # ranges from roughly (0 to 1) * .75\n",
    "    n_crunchy_lower = len(selected_ingredients[selected_ingredients['salad_crunchy'] == 'y'])\n",
    "    n_crunchy_upper = len(selected_ingredients[selected_ingredients['salad_crunchy'] == 'Y'])\n",
    "    n_chewy_lower = len(selected_ingredients[selected_ingredients['salad_chewy'] == 'y'])\n",
    "    n_chewy_upper = len(selected_ingredients[selected_ingredients['salad_chewy'] == 'Y'])\n",
    "    n_juicy_lower = len(selected_ingredients[selected_ingredients['salad_juicy'] == 'y'])\n",
    "    n_juicy_upper = len(selected_ingredients[selected_ingredients['salad_juicy'] == 'Y'])\n",
    "    \n",
    "    # each ranges from roughly 0 to 1\n",
    "    crunchy_score = (n_crunchy_lower/2 + n_crunchy_upper)/3\n",
    "    chewy_score = (n_chewy_lower/2 + n_chewy_upper)\n",
    "    juicy_score = (n_juicy_lower/2 + n_juicy_upper)/3\n",
    "#     print(crunchy_score, chewy_score, juicy_score)\n",
    "    \n",
    "    texture_balance_score = 4 / (1 + abs(1-crunchy_score) + abs(1-chewy_score) + abs(1-juicy_score)) - 1\n",
    "#     print(texture_balance_score)\n",
    "#     print()\n",
    "    \n",
    "    score += texture_balance_score * .75\n",
    "\n",
    "# seems like it's hard to balance food groups on top of everything else. pity the scores aren't more independent\n",
    "# FOOD GROUP BALANCE BONUS =========================================================================================\n",
    "    # ranges from roughly (25 to 1) * 2\n",
    "    n_fruit = len(selected_ingredients[selected_ingredients['fruit'] == 'y'])\n",
    "    n_veg = len(selected_ingredients[selected_ingredients['veg'] == 'y'])\n",
    "    n_protein = len(selected_ingredients[selected_ingredients['protein'] == 'y'])\n",
    "    \n",
    "    # each varies from roughly 0 to 1 (sometimes a little over)\n",
    "    fruit_score = n_fruit / 3\n",
    "    veg_score = n_veg / 5\n",
    "    protein_score = n_protein / 3\n",
    "#     print(fruit_score, veg_score, protein_score)\n",
    "    \n",
    "    food_group_balance_score = 3 / (1 + abs(1-fruit_score) + abs(1-veg_score) + abs(1-protein_score)) - .75\n",
    "#     print(food_group_balance_score)\n",
    "#     print()\n",
    "    \n",
    "    score += food_group_balance_score * 2\n",
    "    \n",
    "    if score > top_score:\n",
    "        top_score = score\n",
    "        top_food_group_balance_score = food_group_balance_score\n",
    "        top_average_shortest_path_score = average_shortest_path_score\n",
    "        top_flavor_balance_score = flavor_balance_score\n",
    "        top_texture_balance_score = texture_balance_score\n",
    "        top_all_clashing_pairs_score = all_clashing_pairs_score\n",
    "        top_pair_strength_score = pair_strength_score\n",
    "#         top_upper_pairs = upper_pairs\n",
    "#         top_lower_pairs = lower_pairs\n",
    "        top_lc_pairs = lower_category_pairs\n",
    "        top_ld_pairs = lower_direct_pairs\n",
    "        top_uc_pairs = upper_category_pairs\n",
    "        top_ud_pairs = upper_direct_pairs\n",
    "        top_selected_ingredients = selected_ingredients\n",
    "        top_average_shortest_path_length = average_shortest_path_length\n",
    "#         top_upper_proportion = len(upper_pairs) / (len(upper_pairs) + len(lower_pairs))\n",
    "# print('TOP AVG SHORTEST PATH LENGTH', top_average_shortest_path_length)\n",
    "# print('TOP UPPER PROPORTION', top_upper_proportion)\n",
    "print('TOP AVERAGE SHORTEST PATH SCORE', top_average_shortest_path_score * 4)\n",
    "print('TOP PAIR STRENGTH SCORE', top_pair_strength_score * 3)\n",
    "print('TOP ALL CLASHING PAIRS SCORE', top_all_clashing_pairs_score * -1.5)\n",
    "print('TOP FLAVOR BALANCE SCORE', top_flavor_balance_score)\n",
    "print('TOP TEXTURE BALANCE SCORE', top_texture_balance_score * .75)\n",
    "print('TOP FOOD GROUP BALANCE SCORE', top_food_group_balance_score * 2)\n",
    "print('TOP_SCORE', top_score)            \n",
    "    \n",
    "top_net = net.Network(notebook=True)\n",
    "\n",
    "nodes = top_selected_ingredients['name'].tolist()\n",
    "\n",
    "def get_color(row):\n",
    "#     print(type(row))\n",
    "#     print(row)\n",
    "    if row['salad_green'] == 'y':\n",
    "        return 'lightgreen'\n",
    "    elif row['salad_extra'] == 'y':\n",
    "        if row['veg'] == 'y':\n",
    "            return 'green'\n",
    "        elif row['fruit'] == 'y':\n",
    "            return 'orange'\n",
    "        elif row['protein_nut_seed'] == 'y':\n",
    "            return 'brown'\n",
    "        else:\n",
    "            return 'lightblue'\n",
    "    elif row['salad_dressing'] == 'y':\n",
    "        return 'lightgrey'\n",
    "    \n",
    "nodes_color = top_selected_ingredients.apply(get_color, axis=1).tolist()\n",
    "\n",
    "top_net.add_nodes(\n",
    "    nodes=nodes,\n",
    "    color=nodes_color\n",
    ")\n",
    "\n",
    "for pair in top_lc_pairs:\n",
    "    top_net.add_edge(pair[0], pair[1], physics=False, color='lightgrey')\n",
    "\n",
    "for pair in top_ld_pairs:\n",
    "    top_net.add_edge(pair[0], pair[1], physics=False, color='grey')\n",
    "    \n",
    "for pair in top_uc_pairs:\n",
    "    top_net.add_edge(pair[0], pair[1], color='darkgrey')\n",
    "    \n",
    "for pair in top_ud_pairs:\n",
    "    top_net.add_edge(pair[0], pair[1], color='black')\n",
    "\n",
    "vegan = top_selected_ingredients['not_vegan'].sum() == ''\n",
    "gluten_free = top_selected_ingredients['gluten'].sum() == ''\n",
    "print(vegan, gluten_free)\n",
    "\n",
    "top_net.show('top_net.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Recording recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SALAD RECIPE DATA IMPORT SUCCESSFUL\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    salad_recipe_data = pd.read_csv(os.path.join(root_path, 'DATA/salad_recipe_data_latest.csv'))\n",
    "    print('SALAD RECIPE DATA IMPORT SUCCESSFUL')\n",
    "except:\n",
    "    salad_recipe_data = pd.DataFrame({\n",
    "        'vegan': [],\n",
    "        'gluten_free': [],\n",
    "        'basic': [],\n",
    "        'best_of': [],\n",
    "        'score': [],\n",
    "        'pairing_density_bonus': [],\n",
    "        'pair_strength_bonus': [],\n",
    "        'clash_penalty': [],\n",
    "        'flavor_balance_bonus': [],\n",
    "        'texture_balance_bonus': [],\n",
    "        'food_group_balance_bonus': [],\n",
    "        'lc_pairs': [],\n",
    "        'ld_pairs': [],\n",
    "        'uc_pairs': [],\n",
    "        'ud_pairs':[],\n",
    "        'clashing_pairs': [],\n",
    "        'ingredient_names': [],\n",
    "        'leafy_green_names': [],\n",
    "        'extra_names': [],\n",
    "        'dressing_names': [],\n",
    "    })\n",
    "    print('IMPORT FAILED, CREATING NEW SALAD RECIPE DATAFRAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "salad_greens = salad_data[salad_data['salad_green'] == 'y']\n",
    "\n",
    "salad_extras = salad_data[salad_data['salad_extra'] == 'y']\n",
    "salad_extra_veg = salad_data[(salad_data['veg'] == 'y') & (salad_data['salad_extra'] == 'y')]\n",
    "salad_extra_fruits = salad_data[(salad_data['fruit'] == 'y') & (salad_data['salad_extra'] == 'y')]\n",
    "salad_extra_nuts = salad_data[(salad_data['protein_seed'] == 'y') & (salad_data['salad_extra'] == 'y')]\n",
    "salad_extra_seeds = salad_data[(salad_data['protein_nut'] == 'y') & (salad_data['salad_extra'] == 'y')]\n",
    "salad_extra_tomatoes = salad_data[salad_data['salad_extra_tomato'] == 'y']\n",
    "salad_extra_olives = salad_data[salad_data['salad_extra_olive'] == 'y']\n",
    "salad_extra_cheeses = salad_data[salad_data['salad_extra_cheese'] == 'y']\n",
    "salad_extra_eggs = salad_data[salad_data['salad_extra_egg'] == 'y']\n",
    "salad_extra_croutons = salad_data[salad_data['salad_extra_crouton'] == 'y']\n",
    "\n",
    "salad_dressing_oils = salad_data[salad_data['salad_dressing_oil'] == 'y']\n",
    "salad_dressing_vinegars = salad_data[salad_data['salad_dressing_vinegar'] == 'y']\n",
    "salad_dressing_salts = salad_data[salad_data['salad_dressing_salt'] == 'y']\n",
    "salad_dressing_peppers = salad_data[salad_data['salad_dressing_pepper'] == 'y']\n",
    "salad_dressing_garlics = salad_data[salad_data['salad_dressing_garlic'] == 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install networkx\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SALAD RECIPE RECORDED. SCORE: 10.84495599436616\n",
      "SALAD RECIPE RECORDED. SCORE: 10.380796536796538\n",
      "SALAD RECIPE RECORDED. SCORE: 9.970445344129555\n",
      "SALAD RECIPE RECORDED. SCORE: 10.502565236620963\n",
      "SALAD RECIPE RECORDED. SCORE: 9.951428571428572\n",
      "SALAD RECIPE RECORDED. SCORE: 10.649220032840724\n",
      "SALAD RECIPE RECORDED. SCORE: 10.501343215358496\n",
      "SALAD RECIPE RECORDED. SCORE: 10.928643351805565\n",
      "SALAD RECIPE RECORDED. SCORE: 10.406142057710003\n",
      "SALAD RECIPE RECORDED. SCORE: 10.057016317016318\n",
      "SALAD RECIPE RECORDED. SCORE: 10.507801418439714\n",
      "SALAD RECIPE RECORDED. SCORE: 11.17917030740409\n",
      "SALAD RECIPE RECORDED. SCORE: 11.152702736467386\n",
      "SALAD RECIPE RECORDED. SCORE: 11.853302611367129\n",
      "SALAD RECIPE RECORDED. SCORE: 10.670695970695972\n",
      "SALAD RECIPE RECORDED. SCORE: 10.918930307165601\n",
      "SALAD RECIPE RECORDED. SCORE: 11.416666666666666\n",
      "SALAD RECIPE RECORDED. SCORE: 11.064540582224794\n",
      "SALAD RECIPE RECORDED. SCORE: 10.0177140101278\n",
      "SALAD RECIPE RECORDED. SCORE: 10.338076923076922\n",
      "SALAD RECIPE RECORDED. SCORE: 11.143884376493073\n",
      "SALAD RECIPE RECORDED. SCORE: 10.735828113042842\n",
      "SALAD RECIPE RECORDED. SCORE: 10.02186483897652\n",
      "SALAD RECIPE RECORDED. SCORE: 10.425974025974025\n",
      "SALAD RECIPE RECORDED. SCORE: 10.525610128400825\n",
      "SALAD RECIPE RECORDED. SCORE: 9.836324731836655\n",
      "SALAD RECIPE RECORDED. SCORE: 10.213103712005072\n",
      "SALAD RECIPE RECORDED. SCORE: 10.710969515242379\n",
      "SALAD RECIPE RECORDED. SCORE: 10.842501540838736\n",
      "SALAD RECIPE RECORDED. SCORE: 10.361138264364069\n",
      "SALAD RECIPE RECORDED. SCORE: 10.116000278790978\n",
      "SALAD RECIPE RECORDED. SCORE: 10.528320802005013\n",
      "SALAD RECIPE RECORDED. SCORE: 9.967490842490843\n",
      "SALAD RECIPE RECORDED. SCORE: 10.87638557095079\n",
      "SALAD RECIPE RECORDED. SCORE: 10.554349680012459\n",
      "SALAD RECIPE RECORDED. SCORE: 11.49830761572922\n",
      "SALAD RECIPE RECORDED. SCORE: 10.125732868757261\n",
      "SALAD RECIPE RECORDED. SCORE: 10.745560162295192\n",
      "SALAD RECIPE RECORDED. SCORE: 10.214796282019579\n",
      "SALAD RECIPE RECORDED. SCORE: 10.666475812088438\n",
      "SALAD RECIPE RECORDED. SCORE: 9.829511278195488\n",
      "SALAD RECIPE RECORDED. SCORE: 10.465791245791245\n",
      "SALAD RECIPE RECORDED. SCORE: 10.406420783416342\n",
      "SALAD RECIPE RECORDED. SCORE: 10.7633024869867\n",
      "SALAD RECIPE RECORDED. SCORE: 10.157948108536344\n",
      "SALAD RECIPE RECORDED. SCORE: 10.911385182323395\n",
      "SALAD RECIPE RECORDED. SCORE: 10.842391045487021\n",
      "SALAD RECIPE RECORDED. SCORE: 10.567841191066996\n",
      "SALAD RECIPE RECORDED. SCORE: 10.275227415380868\n",
      "SALAD RECIPE RECORDED. SCORE: 10.881576514955448\n",
      "SALAD RECIPE RECORDED. SCORE: 10.453571792223661\n",
      "SALAD RECIPE RECORDED. SCORE: 9.712543544404266\n",
      "SALAD RECIPE RECORDED. SCORE: 10.55056419328865\n",
      "SALAD RECIPE RECORDED. SCORE: 11.162470862470862\n",
      "SALAD RECIPE RECORDED. SCORE: 10.0021424275316\n",
      "SALAD RECIPE RECORDED. SCORE: 10.536999667694284\n",
      "SALAD RECIPE RECORDED. SCORE: 10.537802527307775\n",
      "SALAD RECIPE RECORDED. SCORE: 10.450864150453173\n",
      "SALAD RECIPE RECORDED. SCORE: 11.23221420177942\n",
      "SALAD RECIPE RECORDED. SCORE: 10.931654135338345\n",
      "SALAD RECIPE RECORDED. SCORE: 9.724371155160629\n",
      "SALAD RECIPE RECORDED. SCORE: 10.418133759527908\n",
      "SALAD RECIPE RECORDED. SCORE: 10.932161863201989\n",
      "SALAD RECIPE RECORDED. SCORE: 10.856003980539583\n",
      "SALAD RECIPE RECORDED. SCORE: 10.00713889251665\n",
      "SALAD RECIPE RECORDED. SCORE: 10.138725490196078\n",
      "SALAD RECIPE RECORDED. SCORE: 10.085672909313306\n",
      "SALAD RECIPE RECORDED. SCORE: 10.101174457493972\n",
      "SALAD RECIPE RECORDED. SCORE: 10.677742205529663\n",
      "SALAD RECIPE RECORDED. SCORE: 10.56037262471131\n",
      "SALAD RECIPE RECORDED. SCORE: 10.721292778726093\n",
      "SALAD RECIPE RECORDED. SCORE: 11.523809653882452\n",
      "SALAD RECIPE RECORDED. SCORE: 10.1571853866407\n",
      "SALAD RECIPE RECORDED. SCORE: 9.627909803202408\n",
      "SALAD RECIPE RECORDED. SCORE: 10.196183639041525\n",
      "SALAD RECIPE RECORDED. SCORE: 11.321322537112012\n",
      "SALAD RECIPE RECORDED. SCORE: 10.479655472178713\n",
      "SALAD RECIPE RECORDED. SCORE: 10.953981937602626\n",
      "SALAD RECIPE RECORDED. SCORE: 10.078275014459225\n",
      "SALAD RECIPE RECORDED. SCORE: 10.293772893772893\n",
      "SALAD RECIPE RECORDED. SCORE: 9.672294372294374\n",
      "SALAD RECIPE RECORDED. SCORE: 10.012327075098813\n",
      "SALAD RECIPE RECORDED. SCORE: 11.159606758832567\n",
      "SALAD RECIPE RECORDED. SCORE: 10.752534244241513\n",
      "SALAD RECIPE RECORDED. SCORE: 10.101785714285713\n",
      "SALAD RECIPE RECORDED. SCORE: 10.32717058346349\n",
      "SALAD RECIPE RECORDED. SCORE: 10.534508216241964\n",
      "SALAD RECIPE RECORDED. SCORE: 10.483519885687066\n",
      "SALAD RECIPE RECORDED. SCORE: 10.135603855603854\n",
      "SALAD RECIPE RECORDED. SCORE: 10.5265915931028\n",
      "SALAD RECIPE RECORDED. SCORE: 10.386099865047232\n",
      "SALAD RECIPE RECORDED. SCORE: 10.03840803151555\n",
      "SALAD RECIPE RECORDED. SCORE: 10.276056410946707\n",
      "SALAD RECIPE RECORDED. SCORE: 11.186509375231225\n",
      "SALAD RECIPE RECORDED. SCORE: 11.198538799829763\n",
      "SALAD RECIPE RECORDED. SCORE: 9.993610815272005\n",
      "SALAD RECIPE RECORDED. SCORE: 10.402095238095239\n",
      "SALAD RECIPE RECORDED. SCORE: 10.2667430929726\n",
      "SALAD RECIPE RECORDED. SCORE: 10.383750356062814\n",
      "SALAD RECIPE RECORDED. SCORE: 10.57939003187482\n"
     ]
    }
   ],
   "source": [
    "best_of = 300\n",
    "for recipe_count in range(100):\n",
    "    top_score = 0\n",
    "    for i in range(best_of):\n",
    "        n_subgraphs = 2\n",
    "        while n_subgraphs > 1: # keep shuffling until you get a well connected graph\n",
    "            n_greens = random.randrange(2, 4)\n",
    "            n_extras = random.randrange(2, 6)\n",
    "            n_dressing_oils = 1\n",
    "            n_dressing_vinegars = 1\n",
    "            n_dressing_salts = 1\n",
    "            n_dressing_peppers = 1\n",
    "            # n_dressing_garlics = random.randrange(0, 2) # maybe make presence dependent on the rest. or, just leave out for now.\n",
    "\n",
    "            selected_greens = salad_greens.sample(n_greens)\n",
    "            selected_extras = salad_extras.sample(n_extras)\n",
    "            selected_dressing_oils = salad_dressing_oils.sample(n_dressing_oils)\n",
    "            selected_dressing_vinegars = salad_dressing_vinegars.sample(n_dressing_vinegars)\n",
    "            selected_dressing_salts = salad_dressing_salts.sample(n_dressing_salts)\n",
    "            selected_dressing_peppers = salad_dressing_peppers.sample(n_dressing_peppers)\n",
    "            selected_ingredients = selected_greens.append(selected_extras).append(selected_dressing_oils).append(selected_dressing_vinegars).append(selected_dressing_salts).append(selected_dressing_peppers)\n",
    "\n",
    "            lower_category_pairs = []\n",
    "            lower_direct_pairs = []\n",
    "            upper_category_pairs = []\n",
    "            upper_direct_pairs = []\n",
    "            ingredients_list = selected_ingredients['name'].values.tolist()\n",
    "            already_checked = []\n",
    "            for ingredient_name in ingredients_list:\n",
    "                for lc_name in pairing_data['lower_category_names'][pairing_data['name'] == ingredient_name].iloc[0]:\n",
    "                    if lc_name in ingredients_list and not lc_name in already_checked:\n",
    "                        lower_category_pairs.append([ingredient_name, lc_name])\n",
    "                for ld_name in pairing_data['lower_direct_names'][pairing_data['name'] == ingredient_name].iloc[0]:\n",
    "                    if ld_name in ingredients_list and not ld_name in already_checked:\n",
    "                        lower_direct_pairs.append([ingredient_name, ld_name])\n",
    "                for uc_name in pairing_data['upper_category_names'][pairing_data['name'] == ingredient_name].iloc[0]:\n",
    "                    if uc_name in ingredients_list and not uc_name in already_checked:\n",
    "                        upper_category_pairs.append([ingredient_name, uc_name])\n",
    "                for ud_name in pairing_data['upper_direct_names'][pairing_data['name'] == ingredient_name].iloc[0]:\n",
    "                    if ud_name in ingredients_list and not ud_name in already_checked:\n",
    "                        upper_direct_pairs.append([ingredient_name, ud_name])\n",
    "                already_checked.append(ingredient_name)\n",
    "\n",
    "            lower_pairs = lower_category_pairs + lower_direct_pairs\n",
    "            upper_pairs = upper_category_pairs + upper_direct_pairs\n",
    "            all_pairs = lower_pairs + upper_pairs\n",
    "\n",
    "    #         all_pairs_sp = [tuple(sorted(pair)) for pair in all_pairs]\n",
    "    #         print(len(all_pairs_sp), len(list(set(all_pairs_sp))))\n",
    "\n",
    "    #         print('INGREDIENTS', ingredients_list)\n",
    "    #         print()\n",
    "    #         print('LC PAIRS', lower_category_pairs)\n",
    "    #         print()\n",
    "    #         print()\n",
    "\n",
    "            G = nx.Graph()\n",
    "            G.add_nodes_from(selected_ingredients['name'].values.tolist())\n",
    "            G.add_edges_from(all_pairs)\n",
    "            n_subgraphs = len(list(nx.connected_component_subgraphs(G)))\n",
    "\n",
    "        score = 0\n",
    "\n",
    "    # SIMPLER ALTERNATIVE: bonus for proportion of actual pairs over possible pairs? could then combine with pair strength bonus?\n",
    "    # PAIRING DENSITY BONUS ============================================================================================\n",
    "        # ranges from roughly (.1 to 1) * 4\n",
    "        average_shortest_path_length = nx.average_shortest_path_length(G)\n",
    "        average_shortest_path_score = 2.5 / average_shortest_path_length - 1.1\n",
    "    #     print(average_shortest_path_score)\n",
    "        score += average_shortest_path_score * 4    \n",
    "\n",
    "    # # UPPER PAIRING BONUS ==============================================================================================\n",
    "    #     # ranges from roughly (.25 to 1) * 3\n",
    "    #     upper_proportion_score = len(upper_pairs) / len(all_pairs) * 2.5 # messed with this, not sure if it still works\n",
    "    # #     print(upper_proportion_score)\n",
    "    # #     print(len(upper_pairs), len(lower_pairs), len(all_pairs))\n",
    "    # #     print()\n",
    "    #     score += upper_proportion_score * 3\n",
    "\n",
    "    # PAIR STRENGTH BONUS ==============================================================================================\n",
    "        # ranges from roughly (0 to 1) * 3\n",
    "\n",
    "        # I'm thinking of 'lower category' as default, and awarding points for steps up from that\n",
    "        ld_bonus = 1*len(lower_direct_pairs)\n",
    "        uc_bonus = 2*len(upper_category_pairs)\n",
    "        ud_bonus = 5*len(upper_direct_pairs)\n",
    "        pair_strength_score = .6*(ld_bonus + uc_bonus + ud_bonus)/len(all_pairs) # otherwise would tend toward large salads\n",
    "    #     print('LC', len(lower_category_pairs))\n",
    "    #     print('LD', len(lower_direct_pairs))\n",
    "    #     print('UC', len(upper_category_pairs))\n",
    "    #     print('UD', len(upper_direct_pairs))\n",
    "    #     print('SCORE', pair_strength_score)\n",
    "    #     print()\n",
    "        score += pair_strength_score * 3\n",
    "\n",
    "    # important but easy to avoid, so not weighted too heavily\n",
    "    # CLASH PENALTY ====================================================================================================\n",
    "        # ranges from roughly (0 to 1) * -1.5\n",
    "        all_clashing_pairs = []\n",
    "        selected_ingredients_list = selected_ingredients['name'].values.tolist()\n",
    "        for name in selected_ingredients_list:\n",
    "            names_that_clash_with_name = clashes_with_data['all_clashes_with_names'][clashes_with_data['name'] == name].iloc[0]\n",
    "            all_clashing_names = set(selected_ingredients_list).intersection(set(names_that_clash_with_name)) # selected names that clash with this selected name\n",
    "            all_clashing_pairs += [tuple(sorted([name, all_clashing_name])) for all_clashing_name in all_clashing_names]\n",
    "\n",
    "        all_clashing_pairs = list(set(all_clashing_pairs))\n",
    "        all_clashing_pairs_score = len(list(all_clashing_pairs)) / 4\n",
    "        score += len(all_clashing_pairs) * -1.5\n",
    "\n",
    "    # # FRUIT BONUS ======================================================================================================\n",
    "    #     # ranges from roughly (0 to 3) * .1\n",
    "    #     n_fruit = len(selected_ingredients[selected_ingredients['fruit'] == 'y'])\n",
    "    #     score += n_fruit * .1\n",
    "\n",
    "    # # NUT SEED BONUS ===================================================================================================    \n",
    "    #     # ranges from roughly (0 to 2) * .15\n",
    "    #     n_nut_seed = len(selected_ingredients[selected_ingredients['protein_nut_seed'] == 'y'])\n",
    "    #     score += n_nut_seed * .15\n",
    "\n",
    "    # FLAVOR BALANCE BONUS =============================================================================================\n",
    "        # ranges from roughly (0 to 1) * 1\n",
    "        n_sweet_lower = len(selected_ingredients[selected_ingredients['sweet'] == 'y'])\n",
    "        n_sweet_upper = len(selected_ingredients[selected_ingredients['sweet'] == 'Y'])\n",
    "        n_salty_lower = len(selected_ingredients[selected_ingredients['salty'] == 'y'])\n",
    "        n_salty_upper = len(selected_ingredients[selected_ingredients['salty'] == 'Y'])\n",
    "        n_sour_lower = len(selected_ingredients[selected_ingredients['sour'] == 'y'])\n",
    "        n_sour_upper = len(selected_ingredients[selected_ingredients['sour'] == 'Y'])\n",
    "        n_savory_lower = len(selected_ingredients[selected_ingredients['savory'] == 'y'])\n",
    "        n_savory_upper = len(selected_ingredients[selected_ingredients['savory'] == 'Y'])\n",
    "        n_bitter_lower = len(selected_ingredients[selected_ingredients['bitter'] == 'y'])\n",
    "        n_bitter_upper = len(selected_ingredients[selected_ingredients['bitter'] == 'Y'])\n",
    "        n_spicy_lower = len(selected_ingredients[selected_ingredients['spicy'] == 'y'])\n",
    "        n_spicy_upper = len(selected_ingredients[selected_ingredients['spicy'] == 'Y'])\n",
    "\n",
    "        # each varies from roughly .5 to 1\n",
    "        sweet_score = (n_sweet_lower/2 + n_sweet_upper)/5\n",
    "        salty_score = (n_salty_lower/2 + n_salty_upper)*2/5\n",
    "        sour_score = (n_sour_lower/2 + n_sour_upper)*2/5\n",
    "        savory_score = (n_savory_lower/2 + n_savory_upper)*3/5\n",
    "        bitter_score = (n_bitter_lower/2 + n_bitter_upper)*3/5\n",
    "        spicy_score = (n_spicy_lower/2 + n_spicy_upper)*2/5\n",
    "\n",
    "        flavor_balance_score = 5 / (1 + abs(1-sweet_score) + abs(1-salty_score) + abs(1-sour_score) + abs(1-savory_score) + abs(1-spicy_score)) - 1.25\n",
    "    #     print(flavor_balance_score)\n",
    "\n",
    "        score += flavor_balance_score\n",
    "    #     print(sweet_score, salty_score, sour_score, savory_score, bitter_score, spicy_score)\n",
    "    #     print()\n",
    "\n",
    "    #     print(n_sweet_lower, n_sweet_upper)\n",
    "    #     print(n_salty_lower, n_salty_upper)\n",
    "    #     print(n_sour_lower, n_sour_upper)\n",
    "    #     print(n_savory_lower, n_savory_upper)\n",
    "    #     print(n_bitter_lower, n_bitter_upper)\n",
    "    #     print(n_spicy_lower, n_spicy_upper)\n",
    "    #     print()\n",
    "\n",
    "    # TEXTURE BALANCE BONUS ============================================================================================\n",
    "        # ranges from roughly (0 to 1) * .75\n",
    "        n_crunchy_lower = len(selected_ingredients[selected_ingredients['salad_crunchy'] == 'y'])\n",
    "        n_crunchy_upper = len(selected_ingredients[selected_ingredients['salad_crunchy'] == 'Y'])\n",
    "        n_chewy_lower = len(selected_ingredients[selected_ingredients['salad_chewy'] == 'y'])\n",
    "        n_chewy_upper = len(selected_ingredients[selected_ingredients['salad_chewy'] == 'Y'])\n",
    "        n_juicy_lower = len(selected_ingredients[selected_ingredients['salad_juicy'] == 'y'])\n",
    "        n_juicy_upper = len(selected_ingredients[selected_ingredients['salad_juicy'] == 'Y'])\n",
    "\n",
    "        # each ranges from roughly 0 to 1\n",
    "        crunchy_score = (n_crunchy_lower/2 + n_crunchy_upper)/3\n",
    "        chewy_score = (n_chewy_lower/2 + n_chewy_upper)\n",
    "        juicy_score = (n_juicy_lower/2 + n_juicy_upper)/3\n",
    "    #     print(crunchy_score, chewy_score, juicy_score)\n",
    "\n",
    "        texture_balance_score = 4 / (1 + abs(1-crunchy_score) + abs(1-chewy_score) + abs(1-juicy_score)) - 1\n",
    "    #     print(texture_balance_score)\n",
    "    #     print()\n",
    "\n",
    "        score += texture_balance_score * .75\n",
    "\n",
    "    # seems like it's hard to balance food groups on top of everything else. pity the scores aren't more independent\n",
    "    # FOOD GROUP BALANCE BONUS =========================================================================================\n",
    "        # ranges from roughly (25 to 1) * 2\n",
    "        n_fruit = len(selected_ingredients[selected_ingredients['fruit'] == 'y'])\n",
    "        n_veg = len(selected_ingredients[selected_ingredients['veg'] == 'y'])\n",
    "        n_protein = len(selected_ingredients[selected_ingredients['protein'] == 'y'])\n",
    "\n",
    "        # each varies from roughly 0 to 1 (sometimes a little over)\n",
    "        fruit_score = n_fruit / 3\n",
    "        veg_score = n_veg / 5\n",
    "        protein_score = n_protein / 3\n",
    "    #     print(fruit_score, veg_score, protein_score)\n",
    "\n",
    "        food_group_balance_score = 3 / (1 + abs(1-fruit_score) + abs(1-veg_score) + abs(1-protein_score)) - .75\n",
    "    #     print(food_group_balance_score)\n",
    "    #     print()\n",
    "\n",
    "        score += food_group_balance_score * 2\n",
    "\n",
    "        if score > top_score:\n",
    "            top_score = score\n",
    "            top_food_group_balance_score = food_group_balance_score\n",
    "            top_average_shortest_path_score = average_shortest_path_score\n",
    "            top_flavor_balance_score = flavor_balance_score\n",
    "            top_texture_balance_score = texture_balance_score\n",
    "            top_all_clashing_pairs_score = all_clashing_pairs_score\n",
    "            top_pair_strength_score = pair_strength_score\n",
    "    #         top_upper_pairs = upper_pairs\n",
    "    #         top_lower_pairs = lower_pairs\n",
    "            top_lc_pairs = lower_category_pairs\n",
    "            top_ld_pairs = lower_direct_pairs\n",
    "            top_uc_pairs = upper_category_pairs\n",
    "            top_ud_pairs = upper_direct_pairs\n",
    "            top_selected_ingredients = selected_ingredients\n",
    "            top_average_shortest_path_length = average_shortest_path_length\n",
    "            top_all_clashing_pairs = all_clashing_pairs\n",
    "    #         top_upper_proportion = len(upper_pairs) / (len(upper_pairs) + len(lower_pairs))\n",
    "    # print('TOP AVG SHORTEST PATH LENGTH', top_average_shortest_path_length)\n",
    "    # print('TOP UPPER PROPORTION', top_upper_proportion)\n",
    "#     print('TOP AVERAGE SHORTEST PATH SCORE', top_average_shortest_path_score * 4)\n",
    "#     print('TOP PAIR STRENGTH SCORE', top_pair_strength_score * 3)\n",
    "#     print('TOP ALL CLASHING PAIRS SCORE', top_all_clashing_pairs_score * -1.5)\n",
    "#     print('TOP FLAVOR BALANCE SCORE', top_flavor_balance_score)\n",
    "#     print('TOP TEXTURE BALANCE SCORE', top_texture_balance_score * .75)\n",
    "#     print('TOP FOOD GROUP BALANCE SCORE', top_food_group_balance_score * 2)\n",
    "#     print('TOP_SCORE', top_score)  \n",
    "    \n",
    "    vegan = top_selected_ingredients['not_vegan'].sum() == ''\n",
    "    gluten_free = top_selected_ingredients['gluten'].sum() == ''\n",
    "    \n",
    "    recipe_greens = top_selected_ingredients[top_selected_ingredients['salad_green'] == 'y']\n",
    "    recipe_extras = top_selected_ingredients[top_selected_ingredients['salad_extra'] == 'y']\n",
    "    recipe_dressing_oils = top_selected_ingredients[top_selected_ingredients['salad_dressing_oil'] == 'y']\n",
    "    recipe_dressing_vinegars = top_selected_ingredients[top_selected_ingredients['salad_dressing_vinegar'] == 'y']\n",
    "    recipe_dressing_salts = top_selected_ingredients[top_selected_ingredients['salad_dressing_salt'] == 'y']\n",
    "    recipe_dressing_peppers = top_selected_ingredients[top_selected_ingredients['salad_dressing_pepper'] == 'y']\n",
    "    recipe_dressing_garlics = top_selected_ingredients[top_selected_ingredients['salad_dressing_garlic'] == 'y']\n",
    "    # could just select 'salad_dressing', but this includes garlics\n",
    "    recipe_dressing = recipe_dressing_oils.append(recipe_dressing_vinegars).append(recipe_dressing_salts).append(recipe_dressing_peppers)\n",
    "\n",
    "    new_recipe = pd.DataFrame({\n",
    "        'vegan': [vegan],\n",
    "        'gluten_free': [gluten_free],\n",
    "        'basic': [salad_data_is_basic],\n",
    "        'best_of': [best_of],\n",
    "        'score': [top_score],\n",
    "        'pairing_density_bonus': [top_average_shortest_path_score * 4],\n",
    "        'pair_strength_bonus': [top_pair_strength_score * 3],\n",
    "        'clash_penalty': [top_all_clashing_pairs_score * 4],\n",
    "        'flavor_balance_bonus': [top_flavor_balance_score],\n",
    "        'texture_balance_bonus': [top_texture_balance_score * 75],\n",
    "        'food_group_balance_bonus': [top_food_group_balance_score * 2],\n",
    "        'lc_pairs': [top_lc_pairs],\n",
    "        'ld_pairs': [top_ld_pairs],\n",
    "        'uc_pairs': [top_uc_pairs],\n",
    "        'ud_pairs':[top_ud_pairs],\n",
    "        'clashing_pairs': [top_all_clashing_pairs],\n",
    "        'ingredient_names': [top_selected_ingredients['name'].values.tolist()],\n",
    "        'leafy_green_names': [recipe_greens['name'].values.tolist()],\n",
    "        'extra_names': [recipe_extras['name'].values.tolist()],\n",
    "        'dressing_names': [recipe_dressing['name'].values.tolist()],\n",
    "    })\n",
    "    salad_recipe_data = salad_recipe_data.append(new_recipe, sort=False)\n",
    "    print('SALAD RECIPE RECORDED. SCORE:', top_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "date_string = f'{str(today.year)}_{str(today.month)}_{str(today.day)}'\n",
    "\n",
    "salad_recipe_data.to_csv(os.path.join(root_path, 'DATA/salad_recipe_data_latest.csv'), index=False)\n",
    "salad_recipe_data.to_csv(os.path.join(root_path, f'DATA/salad_recipe_data_{date_string}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3. Displaying records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyvis\n",
    "\n",
    "from pyvis import network as net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 10.28669499836548\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"500px\"\n",
       "            height=\"500px\"\n",
       "            src=\"recipe_net.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f43519486a0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe = salad_recipe_data[(salad_recipe_data['basic'] == True) & (salad_recipe_data['vegan'] == True) & salad_recipe_data['gluten_free'] == True].sample(1).iloc[0]\n",
    "recipe_net = net.Network(notebook=True)\n",
    "\n",
    "nodes = recipe['ingredient_names']\n",
    "\n",
    "nodes_color = []\n",
    "for name in recipe['ingredient_names']:\n",
    "    ingredient = salad_data[salad_data['name'] == name].iloc[0]\n",
    "    if ingredient['salad_green'] == 'y':\n",
    "        nodes_color.append('lightgreen')\n",
    "    elif ingredient['salad_extra'] == 'y':\n",
    "        if ingredient['veg'] == 'y':\n",
    "            nodes_color.append('green')\n",
    "        elif ingredient['fruit'] == 'y':\n",
    "            nodes_color.append('orange')\n",
    "        elif ingredient['protein_nut_seed'] == 'y':\n",
    "            nodes_color.append('brown')\n",
    "        else:\n",
    "            nodes_color.append('lightblue')\n",
    "    elif ingredient['salad_dressing'] == 'y':\n",
    "        nodes_color.append('lightgrey')  \n",
    "        \n",
    "recipe_net.add_nodes(\n",
    "    nodes=nodes,\n",
    "    color=nodes_color\n",
    ")\n",
    "\n",
    "for pair in recipe['lc_pairs']:\n",
    "    recipe_net.add_edge(pair[0], pair[1], physics=False, color='lightgrey')\n",
    "\n",
    "for pair in recipe['ld_pairs']:\n",
    "    recipe_net.add_edge(pair[0], pair[1], physics=False, color='grey')\n",
    "    \n",
    "for pair in recipe['uc_pairs']:\n",
    "    recipe_net.add_edge(pair[0], pair[1], color='darkgrey')\n",
    "    \n",
    "for pair in recipe['ud_pairs']:\n",
    "    recipe_net.add_edge(pair[0], pair[1], color='black')\n",
    "\n",
    "if not recipe['vegan']:\n",
    "    print('NOT VEGAN')\n",
    "if not recipe['gluten_free']:\n",
    "    print('CONTAINS GLUTEN')\n",
    "print('SCORE:', recipe['score'])\n",
    "recipe_net.show('recipe_net.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Random control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM SCORE 11.875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"500px\"\n",
       "            height=\"500px\"\n",
       "            src=\"selected_net.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f17b2857f98>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALGORITHM B (random control)\n",
    "n_greens = random.randrange(1, 4)\n",
    "n_extras = random.randrange(0, 10)\n",
    "n_dressing_oils = 1\n",
    "n_dressing_vinegars = 1\n",
    "n_dressing_salts = 1\n",
    "n_dressing_peppers = 1\n",
    "# n_dressing_garlics = random.randrange(0, 2) # maybe make presence dependent on the rest. or, just leave out for now.\n",
    "\n",
    "selected_greens = salad_greens.sample(n_greens)\n",
    "selected_extras = salad_extras.sample(n_extras)\n",
    "selected_dressing_oils = salad_dressing_oils.sample(n_dressing_oils)\n",
    "selected_dressing_vinegars = salad_dressing_vinegars.sample(n_dressing_vinegars)\n",
    "selected_dressing_salts = salad_dressing_salts.sample(n_dressing_salts)\n",
    "selected_dressing_peppers = salad_dressing_peppers.sample(n_dressing_peppers)\n",
    "\n",
    "selected_ingredients = selected_greens.append(selected_extras).append(selected_dressing_oils).append(selected_dressing_vinegars).append(selected_dressing_salts).append(selected_dressing_peppers)\n",
    "\n",
    "upper_pairs = []\n",
    "lower_pairs = []\n",
    "for ingredient_name in selected_ingredients['name']:\n",
    "    for pairs_with_name in pairing_data['upper_pairs_with_names'][pairing_data['name'] == ingredient_name].iloc[0]:\n",
    "        if pairs_with_name in selected_ingredients['name'].values.tolist():\n",
    "#             print('UPPER PAIR:', ingredient_name, 'WITH', pairs_with_name)\n",
    "            upper_pairs.append([ingredient_name, pairs_with_name])\n",
    "    for pairs_with_name in pairing_data['lower_pairs_with_names'][pairing_data['name'] == ingredient_name].iloc[0]:\n",
    "        if pairs_with_name in selected_ingredients['name'].values.tolist():\n",
    "#             print('LOWER PAIR:', ingredient_name, 'WITH', pairs_with_name)\n",
    "            lower_pairs.append([ingredient_name, pairs_with_name])\n",
    "\n",
    "score = (len(upper_pairs) * 3 + len(lower_pairs)) / (n_greens + n_extras)\n",
    "print('RANDOM SCORE', score)\n",
    "\n",
    "\n",
    "\n",
    "random_net = net.Network(notebook=True)\n",
    "\n",
    "nodes = selected_ingredients['name'].tolist()\n",
    "\n",
    "def get_color(row):\n",
    "#     print(type(row))\n",
    "#     print(row)\n",
    "    if row['salad_green'] == 'y':\n",
    "        return 'lightgreen'\n",
    "    elif row['salad_extra'] == 'y':\n",
    "        if row['veg'] == 'y':\n",
    "            return 'green'\n",
    "        elif row['fruit'] == 'y':\n",
    "            return 'orange'\n",
    "        elif row['protein_nut_seed'] == 'y':\n",
    "            return 'brown'\n",
    "        else:\n",
    "            return 'lightblue'\n",
    "    elif row['salad_dressing'] == 'y':\n",
    "        return 'lightgrey'\n",
    "    \n",
    "nodes_color = selected_ingredients.apply(get_color, axis=1).tolist()\n",
    "\n",
    "random_net.add_nodes(\n",
    "    nodes=nodes,\n",
    "    color=nodes_color\n",
    ")\n",
    "\n",
    "\n",
    "for pair in upper_pairs:\n",
    "    random_net.add_edge(pair[0], pair[1], color='black')\n",
    "\n",
    "for pair in lower_pairs:\n",
    "    random_net.add_edge(pair[0], pair[1], physics=False, color='lightgrey')\n",
    "\n",
    "random_net.show('selected_net.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
